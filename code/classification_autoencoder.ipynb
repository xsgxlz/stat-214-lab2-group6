{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.models.efficientnet import MBConvConfig, FusedMBConvConfig\n",
    "\n",
    "import optuna\n",
    "\n",
    "sys.path.append(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling\")\n",
    "from preprocessing import to_NCHW, pad_to_384x384, standardize_images\n",
    "from autoencoder import EfficientNetEncoder, EfficientNetDecoder, AutoencoderConfig\n",
    "from classification import masked_bce_loss, masked_hinge_loss, l1_reg, ConvHead\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = np.load(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/data/array_data.npz\")\n",
    "unlabeled_images, unlabeled_masks, labeled_images, labeled_masks, labels = data[\"unlabeled_images\"], data[\"unlabeled_masks\"], data[\"labeled_images\"], data[\"labeled_masks\"], data[\"labels\"]\n",
    "\n",
    "unlabeled_images = pad_to_384x384(to_NCHW(unlabeled_images))\n",
    "unlabeled_masks = pad_to_384x384(unlabeled_masks)\n",
    "\n",
    "labeled_images = pad_to_384x384(to_NCHW(labeled_images))\n",
    "labeled_masks = pad_to_384x384(labeled_masks)\n",
    "labels = pad_to_384x384(labels)\n",
    "\n",
    "# Convert to tensors and move to GPU\n",
    "unlabeled_images = torch.tensor(unlabeled_images, dtype=torch.float32).to(device)  # [161, 8, 384, 384]\n",
    "unlabeled_masks = torch.tensor(unlabeled_masks, dtype=torch.bool).to(device)    # [161, 384, 384]\n",
    "\n",
    "labeled_images = torch.tensor(labeled_images, dtype=torch.float32).to(device)      # [3, 8, 384, 384]\n",
    "labeled_masks = torch.tensor(labeled_masks, dtype=torch.bool).to(device)        # [3, 384, 384]\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)                      # [3, 384, 384]\n",
    "\n",
    "\n",
    "# Standardize images\n",
    "unlabeled_images, std_channel, mean_channel = standardize_images(unlabeled_images, unlabeled_masks)\n",
    "labeled_images, _, _ = standardize_images(labeled_images, labeled_masks, std_channel, mean_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling/ckpt\"\n",
    "saved_epoch = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 15000, 20000, 25000, 30000, 35000, 40000]\n",
    "\n",
    "all_features = torch.zeros((2, 2, 2, 2, 2, len(saved_epoch), 3, 64, 384, 384)).to(device)\n",
    "\n",
    "num_layers_per_block = [1, 2]\n",
    "augementation = [True, False]\n",
    "for block1, block2, block3, flip, rotate in itertools.product(*[num_layers_per_block] * 3,*[augementation] * 2):\n",
    "    config = AutoencoderConfig(\n",
    "        num_layers_block=[block1, block2, block3],\n",
    "        augmentation_flip=flip,\n",
    "        augmentation_rotate=rotate\n",
    "    )\n",
    "    encoder_config = [\n",
    "        FusedMBConvConfig(1, 3, 1, 16, 16, config.num_layers_block[0]),  # 384x384x8 -> 384x384x16\n",
    "        FusedMBConvConfig(4, 3, 2, 16, 32, config.num_layers_block[1]),  # 384x384x16 -> 192x192x32\n",
    "        MBConvConfig(4, 3, 2, 32, 64, config.num_layers_block[2]),       # 192x192x32 -> 96x96x64\n",
    "    ]\n",
    "\n",
    "    encoder = EfficientNetEncoder(\n",
    "        inverted_residual_setting=encoder_config,\n",
    "        dropout=0.1,\n",
    "        input_channels=8,\n",
    "        last_channel=64,\n",
    "    )\n",
    "\n",
    "    decoder = EfficientNetDecoder()\n",
    "    autoencoder = nn.Sequential(encoder, decoder).train().to(device)\n",
    "\n",
    "    folder_path = os.path.join(ckpt_path, str(config))\n",
    "    \n",
    "    for i, epoch in enumerate(saved_epoch):\n",
    "        autoencoder.load_state_dict(torch.load(os.path.join(folder_path, f\"autoencoder_{epoch}.pth\")))\n",
    "        autoencoder.eval()\n",
    "        with torch.inference_mode():\n",
    "            encoder = autoencoder[0]\n",
    "            features = encoder(labeled_images)\n",
    "            features = nn.functional.interpolate(features, size=384, mode=\"bicubic\", antialias=True)\n",
    "            all_features[block1-1, block2-1, block3-1, int(flip), int(rotate), i] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def train_and_validate(\n",
    "    train_data, train_labels, val_data, val_labels,\n",
    "    in_channels, num_layers, kernel_size, hidden_channels,\n",
    "    epochs, lr, weight_decay, optimizer_class, loss_mix_ratio, l1, class_weight, device\n",
    "):\n",
    "    # Create the classifier\n",
    "    #classifier = nn.Conv2d(in_channels, 1, kernel_size=kernel_size, \n",
    "    #                      padding=\"same\", padding_mode=\"replicate\").to(device)\n",
    "    classifier = ConvHead(in_channels, 1, num_layers, kernel_size, hidden_channels).to(device)\n",
    "    classifier.train()\n",
    "\n",
    "    # Instantiate the optimizer\n",
    "    optimizer = optimizer_class(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        classifier.train()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        pred = classifier(train_data)\n",
    "\n",
    "        bce_loss = masked_bce_loss(pred, train_labels, class_weight=class_weight)\n",
    "        hinge_loss = masked_hinge_loss(pred, train_labels, class_weight=class_weight)\n",
    "\n",
    "        loss = loss_mix_ratio * bce_loss + (1 - loss_mix_ratio) * hinge_loss\n",
    "        # Add L1 regularization\n",
    "        loss = loss + l1 * l1_reg(classifier)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    classifier.eval()\n",
    "    with torch.inference_mode():\n",
    "        val_pred = classifier(val_data)\n",
    "        val_loss, val_acc, val_f1 = masked_hinge_loss(val_pred, val_labels, acc=True, f1=True)\n",
    "\n",
    "    return val_f1, val_acc\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters with updated API calls\n",
    "    epochs = trial.suggest_int(\"epochs\", 0, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"SGD\", \"AdamW\"])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 1, 64)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 10)\n",
    "    loss_mix_ratio = trial.suggest_float(\"loss_mix_ratio\", 0, 1)\n",
    "    l1 = trial.suggest_float(\"l1\", 1e-5, 5e-1, log=True)\n",
    "\n",
    "    block1 = trial.suggest_int(\"block1\", 1, 2)\n",
    "    block2 = trial.suggest_int(\"block2\", 1, 2)\n",
    "    block3 = trial.suggest_int(\"block3\", 1, 2)\n",
    "    flip = trial.suggest_categorical(\"flip\", [True, False])\n",
    "    rotate = trial.suggest_categorical(\"rotate\", [True, False])\n",
    "    autoencoder_epoch = trial.suggest_int(\"autoencoder_epoch\", 0, len(saved_epoch)-1)\n",
    "\n",
    "    with_orginal = trial.suggest_categorical(\"with_orginal\", [True, False])\n",
    "    class_weight = trial.suggest_categorical(\"class_weight\", [\"balanced\", None])\n",
    "\n",
    "    feature = all_features[block1-1, block2-1, block3-1, int(flip), int(rotate), autoencoder_epoch]\n",
    "    feature, _, _ = standardize_images(feature, labeled_masks)\n",
    "\n",
    "    if with_orginal:\n",
    "        feature = torch.cat([feature, labeled_images], dim=1)\n",
    "    \n",
    "    # Map string to actual optimizer class\n",
    "    optimizer_class = torch.optim.SGD if optimizer_name == \"SGD\" else torch.optim.AdamW\n",
    "\n",
    "    # Cross-validation indices (modify as needed)\n",
    "    train_val_idx = [0, 1]\n",
    "    \n",
    "    # Container for metrics from each fold\n",
    "    fold_records_f1 = torch.zeros(len(train_val_idx))  # For F1 (objective)\n",
    "    fold_records_acc = torch.zeros(len(train_val_idx))  # For accuracy (logging)\n",
    "\n",
    "    # Assuming feature and labels are defined globally (e.g., torch tensors)\n",
    "    for i in train_val_idx:\n",
    "        # Leave-one-out style split\n",
    "        train_idx = [j for j in train_val_idx if j != i]\n",
    "        val_idx = [i]\n",
    "\n",
    "        # Get training and validation data\n",
    "        train_data = feature[train_idx]\n",
    "        train_labels = labels[train_idx]\n",
    "        val_data = feature[val_idx]\n",
    "        val_labels = labels[val_idx]\n",
    "\n",
    "        # Train and validate, get both F1 and accuracy\n",
    "        val_f1, val_acc = train_and_validate(\n",
    "            train_data=train_data,\n",
    "            train_labels=train_labels,\n",
    "            val_data=val_data,\n",
    "            val_labels=val_labels,\n",
    "            in_channels=feature.shape[1],\n",
    "            num_layers=num_layers,\n",
    "            kernel_size=kernel_size,\n",
    "            hidden_channels=hidden_channels,\n",
    "            epochs=epochs,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            optimizer_class=optimizer_class,\n",
    "            loss_mix_ratio=loss_mix_ratio,\n",
    "            l1=l1,\n",
    "            class_weight=class_weight,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        fold_records_f1[i] = val_f1\n",
    "        fold_records_acc[i] = val_acc\n",
    "    \n",
    "    avg_f1 = fold_records_f1.mean().item()\n",
    "    avg_acc = fold_records_acc.mean().item()\n",
    "\n",
    "    trial.set_user_attr(\"val_acc\", avg_acc)\n",
    "    #print(f\"Trial {trial.number}: F1 = {avg_f1}, Acc = {avg_acc}\")\n",
    "    \n",
    "    # Return average F1 score across folds\n",
    "    return avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-19 17:50:15,811] A new study created in memory with name: no-name-1276b901-1b0e-4a87-ab56-4f457f3f2f55\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the study by running a number of trials (e.g., 100 trials).\n",
    "study.optimize(objective, n_trials=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"optuna_study_autoencoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(study, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "for key, value in best_params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna.visualization.matplotlib\n",
    "optuna.visualization.matplotlib.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"optuna_study_autoencoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(study, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"optuna_study_autoencoder.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_params\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/optuna/study/study.py:119\u001b[39m, in \u001b[36mStudy.best_params\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbest_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    109\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return parameters of the best trial in the study.\u001b[39;00m\n\u001b[32m    110\u001b[39m \n\u001b[32m    111\u001b[39m \u001b[33;03m    .. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_trial\u001b[49m.params\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/optuna/study/study.py:162\u001b[39m, in \u001b[36mStudy.best_trial\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_multi_objective():\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m best_trial = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_storage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# trials. Note that the behavior is undefined when constrained optimization without the\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# violation value in the best-valued trial.\u001b[39;00m\n\u001b[32m    167\u001b[39m constraints = best_trial.system_attrs.get(_CONSTRAINTS_KEY)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/optuna/storages/_in_memory.py:249\u001b[39m, in \u001b[36mInMemoryStorage.get_best_trial\u001b[39m\u001b[34m(self, study_id)\u001b[39m\n\u001b[32m    246\u001b[39m best_trial_id = \u001b[38;5;28mself\u001b[39m._studies[study_id].best_trial_id\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_trial_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo trials are completed yet.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._studies[study_id].directions) > \u001b[32m1\u001b[39m:\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    252\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "test.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
