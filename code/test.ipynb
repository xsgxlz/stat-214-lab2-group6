{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import optuna\n",
    "\n",
    "sys.path.append(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling\")\n",
    "from preprocessing import to_NCHW, pad_to_384x384, standardize_images\n",
    "from classification import train_and_validate\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = np.load(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/data/array_data.npz\")\n",
    "unlabeled_images, unlabeled_masks, labeled_images, labeled_masks, labels = data[\"unlabeled_images\"], data[\"unlabeled_masks\"], data[\"labeled_images\"], data[\"labeled_masks\"], data[\"labels\"]\n",
    "\n",
    "unlabeled_images = pad_to_384x384(to_NCHW(unlabeled_images))\n",
    "unlabeled_masks = pad_to_384x384(unlabeled_masks)\n",
    "\n",
    "labeled_images = pad_to_384x384(to_NCHW(labeled_images))\n",
    "labeled_masks = pad_to_384x384(labeled_masks)\n",
    "labels = pad_to_384x384(labels)\n",
    "\n",
    "# Convert to tensors and move to GPU\n",
    "unlabeled_images = torch.tensor(unlabeled_images, dtype=torch.float32).to(device)  # [161, 8, 384, 384]\n",
    "unlabeled_masks = torch.tensor(unlabeled_masks, dtype=torch.bool).to(device)    # [161, 384, 384]\n",
    "\n",
    "labeled_images = torch.tensor(labeled_images, dtype=torch.float32).to(device)      # [3, 8, 384, 384]\n",
    "labeled_masks = torch.tensor(labeled_masks, dtype=torch.bool).to(device)        # [3, 384, 384]\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)                      # [3, 384, 384]\n",
    "\n",
    "\n",
    "# Standardize images\n",
    "unlabeled_images, std_channel, mean_channel = standardize_images(unlabeled_images, unlabeled_masks)\n",
    "labeled_images, _, _ = standardize_images(labeled_images, labeled_masks, std_channel, mean_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/jet/home/azhang19/optuna_study_original.pkl\", \"rb\") as f:\n",
    "    study = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.79999533, 0.84950012]), array([0.02407335, 0.01626197]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = labeled_images\n",
    "feature, _, _ = standardize_images(feature, labeled_masks)\n",
    "\n",
    "record = np.zeros((10, 2))\n",
    "classifiers = []\n",
    "\n",
    "for repeat in range(10):\n",
    "\n",
    "    train_val_idx = [0, 1]\n",
    "\n",
    "    # Container for metrics from each fold\n",
    "    fold_records_f1 = torch.zeros(len(train_val_idx))  # For F1 (objective)\n",
    "    fold_records_acc = torch.zeros(len(train_val_idx))  # For accuracy (logging)\n",
    "\n",
    "    classifiers_in_this_repeat = []\n",
    "    # Assuming feature and labels are defined globally (e.g., torch tensors)\n",
    "    for i in train_val_idx:\n",
    "        # Leave-one-out style split\n",
    "        train_idx = [j for j in train_val_idx if j != i]\n",
    "        val_idx = [i]\n",
    "\n",
    "        # Get training and validation data\n",
    "        train_data = feature[train_idx]\n",
    "        train_labels = labels[train_idx]\n",
    "        val_data = feature[val_idx]\n",
    "        val_labels = labels[val_idx]\n",
    "\n",
    "        # Train and validate, get both F1 and accuracy\n",
    "        classifier, val_f1, val_acc = train_and_validate(\n",
    "            train_data=train_data,\n",
    "            train_labels=train_labels,\n",
    "            val_data=val_data,\n",
    "            val_labels=val_labels,\n",
    "            in_channels=feature.shape[1],\n",
    "            num_layers=study.best_params[\"num_layers\"],\n",
    "            kernel_size=study.best_params[\"kernel_size\"],\n",
    "            hidden_channels=study.best_params[\"hidden_channels\"],\n",
    "            epochs=study.best_params[\"epochs\"],\n",
    "            lr=study.best_params[\"lr\"],\n",
    "            weight_decay=study.best_params[\"weight_decay\"],\n",
    "            optimizer_class=torch.optim.AdamW,\n",
    "            loss_mix_ratio=study.best_params[\"loss_mix_ratio\"],\n",
    "            l1=study.best_params[\"l1\"],\n",
    "            class_weight=\"balanced\",\n",
    "            device=device,\n",
    "            return_classifier=True,\n",
    "        )\n",
    "        classifiers_in_this_repeat.append((train_idx, classifier))\n",
    "\n",
    "        fold_records_f1[i] = val_f1\n",
    "        fold_records_acc[i] = val_acc\n",
    "\n",
    "    classifiers.append(classifiers_in_this_repeat)\n",
    "    avg_f1 = fold_records_f1.mean().item()\n",
    "    avg_acc = fold_records_acc.mean().item()\n",
    "\n",
    "    record[repeat] = [avg_f1, avg_acc]\n",
    "\n",
    "record.mean(axis=0), record.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1],\n",
       " ConvHead(\n",
       "   (layers): Sequential(\n",
       "     (0): ConvBlock(\n",
       "       (conv): Conv2d(8, 54, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bn): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (activation): SiLU()\n",
       "     )\n",
       "     (1): ConvBlock(\n",
       "       (conv): Conv2d(54, 54, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "       (bn): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (activation): SiLU()\n",
       "     )\n",
       "     (2): Conv2d(54, 1, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat 0, trained on 1, and validated on 0\n",
    "classifiers[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 4.0932,  4.0932,  4.0932,  ...,  1.5397,  4.0932,  4.0932],\n",
       "          [ 4.0932,  4.0932,  4.0932,  ...,  0.6036,  4.0932,  4.0932],\n",
       "          [ 4.0932,  4.0932,  4.0932,  ..., -2.3120,  4.0932,  4.0932],\n",
       "          ...,\n",
       "          [ 4.0932,  4.0932,  4.0932,  ...,  4.0932,  4.0932,  4.0932],\n",
       "          [ 4.0932,  4.0932,  4.0932,  ...,  4.0932,  4.0932,  4.0932],\n",
       "          [ 4.0932,  4.0932,  4.0932,  ...,  4.0932,  4.0932,  4.0932]]]],\n",
       "       device='cuda:0', grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validated on 0\n",
    "classifiers[0][0][1](labeled_images[0:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
