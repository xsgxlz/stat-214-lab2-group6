{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/azhang19/.conda/envs/env_214/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.models.efficientnet import MBConvConfig, FusedMBConvConfig\n",
    "\n",
    "import optuna\n",
    "\n",
    "sys.path.append(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling\")\n",
    "from preprocessing import to_NCHW, pad_to_384x384, standardize_images\n",
    "from autoencoder import EfficientNetEncoder, EfficientNetDecoder, AutoencoderConfig\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = np.load(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/data/array_data.npz\")\n",
    "unlabeled_images, unlabeled_masks, labeled_images, labeled_masks, labels = data[\"unlabeled_images\"], data[\"unlabeled_masks\"], data[\"labeled_images\"], data[\"labeled_masks\"], data[\"labels\"]\n",
    "\n",
    "unlabeled_images = pad_to_384x384(to_NCHW(unlabeled_images))\n",
    "unlabeled_masks = pad_to_384x384(unlabeled_masks)\n",
    "\n",
    "labeled_images = pad_to_384x384(to_NCHW(labeled_images))\n",
    "labeled_masks = pad_to_384x384(labeled_masks)\n",
    "labels = pad_to_384x384(labels)\n",
    "\n",
    "# Convert to tensors and move to GPU\n",
    "unlabeled_images = torch.tensor(unlabeled_images, dtype=torch.float32).to(device)  # [161, 8, 384, 384]\n",
    "unlabeled_masks = torch.tensor(unlabeled_masks, dtype=torch.bool).to(device)    # [161, 384, 384]\n",
    "\n",
    "labeled_images = torch.tensor(labeled_images, dtype=torch.float32).to(device)      # [3, 8, 384, 384]\n",
    "labeled_masks = torch.tensor(labeled_masks, dtype=torch.bool).to(device)        # [3, 384, 384]\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)                      # [3, 384, 384]\n",
    "\n",
    "\n",
    "# Standardize images\n",
    "unlabeled_images, std_channel, mean_channel = standardize_images(unlabeled_images, unlabeled_masks)\n",
    "labeled_images, _, _ = standardize_images(labeled_images, labeled_masks, std_channel, mean_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config = [\n",
    "    FusedMBConvConfig(1, 3, 1, 16, 16, 1),  # 384x384x8 -> 384x384x16\n",
    "    FusedMBConvConfig(4, 3, 2, 16, 32, 1),  # 384x384x16 -> 192x192x32\n",
    "    MBConvConfig(4, 3, 2, 32, 64, 1),       # 192x192x32 -> 96x96x64\n",
    "]\n",
    "\n",
    "# Build encoder and decoder\n",
    "encoder = EfficientNetEncoder(\n",
    "    inverted_residual_setting=encoder_config,\n",
    "    dropout=0.1,\n",
    "    input_channels=8,\n",
    "    last_channel=64,\n",
    ")\n",
    "\n",
    "decoder = EfficientNetDecoder()\n",
    "\n",
    "autoencoder = nn.Sequential(encoder, decoder).train().to(device)\n",
    "autoencoder.load_state_dict(torch.load(f\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling/ckpt/AutoencoderConfig([1, 1, 1], flip=True, rotate=True)/autoencoder_12800.pth\"))\n",
    "\n",
    "encoder = encoder.eval()\n",
    "with torch.inference_mode():\n",
    "    feature = encoder(labeled_images)\n",
    "    feature = nn.functional.interpolate(feature, size=384, mode=\"bicubic\", antialias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_reg(model):\n",
    "    l1 = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"bias\" not in name:\n",
    "            l1 += torch.norm(param, p=1)\n",
    "    return l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred_class, target):\n",
    "    return (pred_class == target).float().mean()\n",
    "\n",
    "def marco_f1_score(pred_class, target):\n",
    "    # F1 for positive class (1)\n",
    "    tp_pos = ((pred_class == 1) & (target == 1)).sum().float()\n",
    "    fp_pos = ((pred_class == 1) & (target == 0)).sum().float()\n",
    "    fn_pos = ((pred_class == 0) & (target == 1)).sum().float()\n",
    "    f1_pos = 2 * tp_pos / (2 * tp_pos + fp_pos + fn_pos + 1e-8)\n",
    "\n",
    "    # F1 for negative class (-1, mapped to 0)\n",
    "    tp_neg = ((pred_class == 0) & (target == 0)).sum().float()\n",
    "    fp_neg = ((pred_class == 0) & (target == 1)).sum().float()\n",
    "    fn_neg = ((pred_class == 1) & (target == 0)).sum().float()\n",
    "    f1_neg = 2 * tp_neg / (2 * tp_neg + fp_neg + fn_neg + 1e-8)\n",
    "\n",
    "    macro_f1 = (f1_pos + f1_neg) / 2\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_bce_loss_acc(pred, label):\n",
    "    # pred: (N, 1, H, W); label: (N, H, W), with label values -1 (negative), 1 (positive), 0 (masked)\n",
    "    pred = pred.flatten()\n",
    "    label = label.flatten()\n",
    "    mask = (label != 0)     # valid indices\n",
    "\n",
    "    pred_valid = pred[mask]\n",
    "    label_valid = label[mask]\n",
    "\n",
    "    # -1/1 -> 0/1\n",
    "    target_valid = (label_valid + 1) / 2\n",
    "\n",
    "    # Compute binary cross entropy loss with logits\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_valid, target_valid)\n",
    "\n",
    "    pred_class = (pred_valid > 0).float()\n",
    "\n",
    "    return loss, accuracy(pred_class, target_valid), marco_f1_score(pred_class, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters with updated API calls.\n",
    "    epochs = trial.suggest_int(\"epochs\", 200, 600)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"SGD\", \"AdamW\"])\n",
    "    kernel_size = trial.suggest_categorical(\"kernel_size\", [1, 2, 3])\n",
    "    loss_name = trial.suggest_categorical(\"loss_fn\", [\"bce\"])#, \"soft_margin\"])\n",
    "    l1 = trial.suggest_float(\"l1\", 1e-5, 1e-1, log=True)\n",
    "    \n",
    "    # Map string to actual optimizer class.\n",
    "    optimizer_class = torch.optim.SGD if optimizer_name == \"SGD\" else torch.optim.AdamW\n",
    "\n",
    "    # Map string to loss function (assumes these are defined).\n",
    "    loss_fn = masked_bce_loss_acc# if loss_name == \"bce\" else masked_soft_margin_loss\n",
    "\n",
    "    # Cross-validation indices (modify as needed)\n",
    "    train_val_idx = [0, 1]\n",
    "    \n",
    "    # Container for metrics from each fold.\n",
    "    fold_records = torch.zeros(len(train_val_idx))\n",
    "\n",
    "    for i in train_val_idx:\n",
    "        # Use leave-one-out style split over train_val_idx.\n",
    "        train_idx = [j for j in train_val_idx if j != i]\n",
    "        val_idx = [i]\n",
    "\n",
    "        # Create the classifier with the chosen kernel size.\n",
    "        classifier = nn.Conv2d(64, 1, kernel_size=kernel_size, \n",
    "                               padding=\"same\", padding_mode=\"replicate\").to(device)\n",
    "        classifier.train()\n",
    "\n",
    "        # Instantiate the optimizer with chosen hyperparameters.\n",
    "        classifier_optimizer = optimizer_class(classifier.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        # Get training and validation data (assumes feature and labels are defined).\n",
    "        train = feature[train_idx]\n",
    "        train_labels = labels[train_idx]\n",
    "        val = feature[val_idx]\n",
    "        val_labels = labels[val_idx]\n",
    "        \n",
    "        # Record metrics for each epoch: [train_loss, train_acc, train_f1, val_loss, val_acc, val_f1].\n",
    "        for epoch in range(epochs):\n",
    "            # Training step.\n",
    "            classifier.train()\n",
    "            classifier_optimizer.zero_grad(set_to_none=True)\n",
    "            pred = classifier(train)\n",
    "            loss, acc, f1 = loss_fn(pred, train_labels)\n",
    "            # Add l1 regularization.\n",
    "            loss = loss + l1 * l1_reg(classifier)\n",
    "            loss.backward()\n",
    "            classifier_optimizer.step()\n",
    "            \n",
    "        # Evaluate on validation set (inference mode).\n",
    "        classifier.eval()\n",
    "        with torch.inference_mode():\n",
    "            val_pred = classifier(val)\n",
    "            val_loss, val_acc, val_f1 = loss_fn(val_pred, val_labels)\n",
    "        \n",
    "        fold_records[i] = val_f1\n",
    "    \n",
    "    # Average metrics across folds (folds x epochs x metrics).\n",
    "    return fold_records.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-08 03:39:19,531] A new study created in memory with name: no-name-d7b24191-189b-4594-b581-a398451f7f93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-08 03:39:20,842] Trial 0 finished with value: 0.6958315968513489 and parameters: {'epochs': 236, 'lr': 0.0003109685945826442, 'weight_decay': 0.02201885603338423, 'optimizer': 'AdamW', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 0.01021019434109759}. Best is trial 0 with value: 0.6958315968513489.\n",
      "[I 2025-03-08 03:39:23,400] Trial 1 finished with value: 0.7348808646202087 and parameters: {'epochs': 561, 'lr': 0.0031996421692630397, 'weight_decay': 0.005877214620126896, 'optimizer': 'AdamW', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 0.060368648473350627}. Best is trial 1 with value: 0.7348808646202087.\n",
      "[I 2025-03-08 03:39:25,899] Trial 2 finished with value: 0.7406752109527588 and parameters: {'epochs': 474, 'lr': 0.00027993568979523437, 'weight_decay': 0.00023106337374583777, 'optimizer': 'AdamW', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 7.407924939164565e-05}. Best is trial 2 with value: 0.7406752109527588.\n",
      "[I 2025-03-08 03:39:27,573] Trial 3 finished with value: 0.7691325545310974 and parameters: {'epochs': 323, 'lr': 0.012087771955650637, 'weight_decay': 0.0007513084182327653, 'optimizer': 'AdamW', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0005027330451587203}. Best is trial 3 with value: 0.7691325545310974.\n",
      "[I 2025-03-08 03:39:29,547] Trial 4 finished with value: 0.7169127464294434 and parameters: {'epochs': 434, 'lr': 0.00018001090881699335, 'weight_decay': 0.0003195937648830432, 'optimizer': 'AdamW', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 0.0012294484818637667}. Best is trial 3 with value: 0.7691325545310974.\n",
      "[I 2025-03-08 03:39:30,818] Trial 5 finished with value: 0.7578259706497192 and parameters: {'epochs': 248, 'lr': 0.00016642999892521644, 'weight_decay': 0.06836886486734375, 'optimizer': 'AdamW', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.01666568713669171}. Best is trial 3 with value: 0.7691325545310974.\n",
      "[I 2025-03-08 03:39:31,858] Trial 6 finished with value: 0.74835205078125 and parameters: {'epochs': 223, 'lr': 0.00839385694544003, 'weight_decay': 0.1818697994364874, 'optimizer': 'AdamW', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 0.0037531350828221436}. Best is trial 3 with value: 0.7691325545310974.\n",
      "[I 2025-03-08 03:39:33,328] Trial 7 finished with value: 0.7290536165237427 and parameters: {'epochs': 279, 'lr': 0.0002810167833402551, 'weight_decay': 0.020068230750595748, 'optimizer': 'AdamW', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00011023585971059414}. Best is trial 3 with value: 0.7691325545310974.\n",
      "[I 2025-03-08 03:39:34,574] Trial 8 finished with value: 0.7633109092712402 and parameters: {'epochs': 254, 'lr': 0.0952639486475308, 'weight_decay': 0.0033410420171678546, 'optimizer': 'AdamW', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0006131491021653758}. Best is trial 3 with value: 0.7691325545310974.\n",
      "[I 2025-03-08 03:39:36,090] Trial 9 finished with value: 0.6809780597686768 and parameters: {'epochs': 344, 'lr': 0.0005061367738402493, 'weight_decay': 0.002191497025783421, 'optimizer': 'SGD', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 0.010593102344893768}. Best is trial 3 with value: 0.7691325545310974.\n",
      "[I 2025-03-08 03:39:37,957] Trial 10 finished with value: 0.7520453929901123 and parameters: {'epochs': 357, 'lr': 0.031830898319979886, 'weight_decay': 1.6372709495468285e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 1.3475958675384007e-05}. Best is trial 3 with value: 0.7691325545310974.\n",
      "[I 2025-03-08 03:39:39,585] Trial 11 finished with value: 0.7524959444999695 and parameters: {'epochs': 334, 'lr': 0.08785391022600436, 'weight_decay': 0.0007608871572209422, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00040064914118637004}. Best is trial 3 with value: 0.7691325545310974.\n",
      "[I 2025-03-08 03:39:41,039] Trial 12 finished with value: 0.7708390951156616 and parameters: {'epochs': 301, 'lr': 0.020663505224471124, 'weight_decay': 5.08174417316856e-05, 'optimizer': 'AdamW', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0004949803650048294}. Best is trial 12 with value: 0.7708390951156616.\n",
      "[I 2025-03-08 03:39:42,548] Trial 13 finished with value: 0.7723309993743896 and parameters: {'epochs': 307, 'lr': 0.012091318209154515, 'weight_decay': 2.516263393723479e-05, 'optimizer': 'AdamW', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00015191441838766025}. Best is trial 13 with value: 0.7723309993743896.\n",
      "[I 2025-03-08 03:39:44,527] Trial 14 finished with value: 0.7798396348953247 and parameters: {'epochs': 407, 'lr': 0.0018901663351377112, 'weight_decay': 1.4346169115112133e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 7.276809262823529e-05}. Best is trial 14 with value: 0.7798396348953247.\n",
      "[I 2025-03-08 03:39:46,480] Trial 15 finished with value: 0.7775655388832092 and parameters: {'epochs': 403, 'lr': 0.0013407671853588228, 'weight_decay': 2.3424312267487785e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 1.0711126801329314e-05}. Best is trial 14 with value: 0.7798396348953247.\n",
      "[I 2025-03-08 03:39:48,886] Trial 16 finished with value: 0.7565504312515259 and parameters: {'epochs': 499, 'lr': 0.001168698936581008, 'weight_decay': 7.797809420356296e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 1.5435986767632053e-05}. Best is trial 14 with value: 0.7798396348953247.\n",
      "[I 2025-03-08 03:39:50,847] Trial 17 finished with value: 0.7958267331123352 and parameters: {'epochs': 400, 'lr': 0.0017090213677660904, 'weight_decay': 1.0720435679591331e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 3.663976112881293e-05}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:39:52,778] Trial 18 finished with value: 0.7946714162826538 and parameters: {'epochs': 392, 'lr': 0.003519973582534154, 'weight_decay': 8.516761668372703e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 3.903627354350667e-05}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:39:55,061] Trial 19 finished with value: 0.7767494320869446 and parameters: {'epochs': 466, 'lr': 0.005579531529912157, 'weight_decay': 0.00011508144904392278, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 3.504436287778939e-05}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:39:57,718] Trial 20 finished with value: 0.7756228446960449 and parameters: {'epochs': 543, 'lr': 0.0007162114836998019, 'weight_decay': 0.6059429610322372, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 3.248453530142064e-05}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:39:59,542] Trial 21 finished with value: 0.782320499420166 and parameters: {'epochs': 393, 'lr': 0.002198209235387632, 'weight_decay': 1.3791598645285605e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 4.3157371440691654e-05}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:01,414] Trial 22 finished with value: 0.7885791063308716 and parameters: {'epochs': 374, 'lr': 0.0030808577980556105, 'weight_decay': 5.3023981063818925e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 3.770589979661898e-05}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:03,255] Trial 23 finished with value: 0.7634873390197754 and parameters: {'epochs': 371, 'lr': 0.005283712017937992, 'weight_decay': 6.359550240587326e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00017286832830941612}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:05,321] Trial 24 finished with value: 0.7698100805282593 and parameters: {'epochs': 436, 'lr': 0.0036463753678029963, 'weight_decay': 1.0091810869926826e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 2.5976722456712293e-05}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:07,790] Trial 25 finished with value: 0.7629228234291077 and parameters: {'epochs': 522, 'lr': 0.0010282484148452279, 'weight_decay': 0.0002045519540170639, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00021159881698250022}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:09,925] Trial 26 finished with value: 0.7881286144256592 and parameters: {'epochs': 438, 'lr': 0.002107027225246432, 'weight_decay': 0.0005679331484208869, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0013911150221577028}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:12,703] Trial 27 finished with value: 0.7703154683113098 and parameters: {'epochs': 593, 'lr': 0.004815129202300667, 'weight_decay': 3.414508618501164e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 2.0706041362412682e-05}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:14,554] Trial 28 finished with value: 0.7307223081588745 and parameters: {'epochs': 386, 'lr': 0.0007296007176403464, 'weight_decay': 4.7385352508370626e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 4.968664587534364e-05}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:16,779] Trial 29 finished with value: 0.7565782070159912 and parameters: {'epochs': 465, 'lr': 0.00813490288646214, 'weight_decay': 0.000122998376281619, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.002372541584624395}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:17,694] Trial 30 finished with value: 0.7419583201408386 and parameters: {'epochs': 200, 'lr': 0.0023328892412373143, 'weight_decay': 0.0017814598669214916, 'optimizer': 'SGD', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 0.00025761825271535704}. Best is trial 17 with value: 0.7958267331123352.\n",
      "[I 2025-03-08 03:40:19,686] Trial 31 finished with value: 0.806543231010437 and parameters: {'epochs': 429, 'lr': 0.0017264387196285402, 'weight_decay': 0.0006772596745653747, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0013059217589111644}. Best is trial 31 with value: 0.806543231010437.\n",
      "[I 2025-03-08 03:40:21,724] Trial 32 finished with value: 0.7844189405441284 and parameters: {'epochs': 420, 'lr': 0.0033655709108578427, 'weight_decay': 0.0003076716208538691, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00422134038815661}. Best is trial 31 with value: 0.806543231010437.\n",
      "[I 2025-03-08 03:40:23,423] Trial 33 finished with value: 0.809642493724823 and parameters: {'epochs': 367, 'lr': 0.0015877496062249453, 'weight_decay': 0.00011100552868718404, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 8.352957541472454e-05}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:25,108] Trial 34 finished with value: 0.6502259969711304 and parameters: {'epochs': 359, 'lr': 0.00047429446114848766, 'weight_decay': 0.009839876793795489, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0021488994054952677}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:27,486] Trial 35 finished with value: 0.783645510673523 and parameters: {'epochs': 490, 'lr': 0.0015566122080278007, 'weight_decay': 0.0011418301884466308, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 5.944286144435641e-05}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:29,469] Trial 36 finished with value: 0.707381010055542 and parameters: {'epochs': 447, 'lr': 0.0008586070120356702, 'weight_decay': 0.00015286866532947108, 'optimizer': 'SGD', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 0.0365809236399427}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:31,415] Trial 37 finished with value: 0.740976870059967 and parameters: {'epochs': 417, 'lr': 0.0004722614180407962, 'weight_decay': 0.0006927705043219325, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 9.965429927663446e-05}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:33,005] Trial 38 finished with value: 0.7816152572631836 and parameters: {'epochs': 317, 'lr': 0.0014764125535233837, 'weight_decay': 0.0003277342592050421, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.00029486778820148225}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:34,435] Trial 39 finished with value: 0.7715262174606323 and parameters: {'epochs': 288, 'lr': 0.00755892532203826, 'weight_decay': 0.004449429980002113, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.000681348470304258}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:35,966] Trial 40 finished with value: 0.7794609069824219 and parameters: {'epochs': 341, 'lr': 0.00011192019689726043, 'weight_decay': 9.78099630891157e-05, 'optimizer': 'AdamW', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 9.739015969893652e-05}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:37,809] Trial 41 finished with value: 0.7915071845054626 and parameters: {'epochs': 378, 'lr': 0.0027432313525022714, 'weight_decay': 2.631201925474143e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 1.9209844379987868e-05}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:39,567] Trial 42 finished with value: 0.7999187111854553 and parameters: {'epochs': 385, 'lr': 0.002622789690258049, 'weight_decay': 3.180518999990956e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 1.7238768695842002e-05}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:41,753] Trial 43 finished with value: 0.7787745594978333 and parameters: {'epochs': 454, 'lr': 0.004229048727221537, 'weight_decay': 0.00038468258582244965, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 1.0651602135998589e-05}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:43,479] Trial 44 finished with value: 0.7920417189598083 and parameters: {'epochs': 360, 'lr': 0.001922121278237935, 'weight_decay': 0.00018465795964106932, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0009878685868818966}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:45,539] Trial 45 finished with value: 0.778206467628479 and parameters: {'epochs': 422, 'lr': 0.0010017061376064538, 'weight_decay': 3.6857793620803944e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 2.299189292592566e-05}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:47,463] Trial 46 finished with value: 0.7713002562522888 and parameters: {'epochs': 395, 'lr': 0.010863092913485379, 'weight_decay': 1.0152040098963867e-05, 'optimizer': 'AdamW', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00013491282727787874}. Best is trial 33 with value: 0.809642493724823.\n",
      "[I 2025-03-08 03:40:49,016] Trial 47 finished with value: 0.8262251615524292 and parameters: {'epochs': 325, 'lr': 0.0003618543621266028, 'weight_decay': 1.979201053287094e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0047670779365748895}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:40:50,403] Trial 48 finished with value: 0.7567042112350464 and parameters: {'epochs': 268, 'lr': 0.00021146941663096363, 'weight_decay': 2.042097943387213e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.005306601997400831}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:40:52,042] Trial 49 finished with value: 0.7414876222610474 and parameters: {'epochs': 321, 'lr': 0.00031022721122314157, 'weight_decay': 2.898747618869783e-05, 'optimizer': 'AdamW', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.014603105868849605}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:40:53,698] Trial 50 finished with value: 0.769837498664856 and parameters: {'epochs': 337, 'lr': 0.0005940380269513699, 'weight_decay': 0.05010138233681366, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.034881012284342615}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:40:55,465] Trial 51 finished with value: 0.7970808744430542 and parameters: {'epochs': 353, 'lr': 0.0013168815636903067, 'weight_decay': 6.981029117068913e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 7.431082408694205e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:40:57,306] Trial 52 finished with value: 0.7837882041931152 and parameters: {'epochs': 354, 'lr': 0.0014795187552422147, 'weight_decay': 1.511422109731859e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.006028061211627556}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:40:59,354] Trial 53 finished with value: 0.7935440540313721 and parameters: {'epochs': 410, 'lr': 0.0011367027731507596, 'weight_decay': 4.492156132622014e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0018984932704135373}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:00,795] Trial 54 finished with value: 0.7895412445068359 and parameters: {'epochs': 293, 'lr': 0.0003940362251536449, 'weight_decay': 8.500978150995213e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.008086222399796002}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:02,459] Trial 55 finished with value: 0.7874650359153748 and parameters: {'epochs': 331, 'lr': 0.0016877620825744221, 'weight_decay': 1.7947512786160084e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 6.431223439770146e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:03,949] Trial 56 finished with value: 0.6409994959831238 and parameters: {'epochs': 305, 'lr': 0.00022129511327049708, 'weight_decay': 6.625919942151938e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.002860408576477353}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:05,676] Trial 57 finished with value: 0.7919557094573975 and parameters: {'epochs': 375, 'lr': 0.0026038515969451876, 'weight_decay': 3.5326412224049546e-05, 'optimizer': 'SGD', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 1.5133433411682326e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:07,508] Trial 58 finished with value: 0.7608082294464111 and parameters: {'epochs': 353, 'lr': 0.0008242734647396178, 'weight_decay': 0.0014373212401298126, 'optimizer': 'AdamW', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0004274717724185977}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:09,577] Trial 59 finished with value: 0.7568273544311523 and parameters: {'epochs': 401, 'lr': 0.0012991609705902685, 'weight_decay': 0.0001437983667510617, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0006864454286048011}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:11,757] Trial 60 finished with value: 0.615003764629364 and parameters: {'epochs': 429, 'lr': 0.0001342827844332667, 'weight_decay': 0.00024613283706520093, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0014072335360134727}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:13,547] Trial 61 finished with value: 0.7782044410705566 and parameters: {'epochs': 389, 'lr': 0.004019718685470052, 'weight_decay': 7.510155270830372e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 2.9992656836490522e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:15,348] Trial 62 finished with value: 0.7883902788162231 and parameters: {'epochs': 364, 'lr': 0.002930247890952665, 'weight_decay': 0.0005229238791982914, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 4.377114373617813e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:17,254] Trial 63 finished with value: 0.7630407214164734 and parameters: {'epochs': 385, 'lr': 0.005373545083066253, 'weight_decay': 1.2272382710242832e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 9.728000297052132e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:19,232] Trial 64 finished with value: 0.7699449062347412 and parameters: {'epochs': 398, 'lr': 0.006953260850877438, 'weight_decay': 2.013602344385113e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 7.282521349042466e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:20,896] Trial 65 finished with value: 0.7802032232284546 and parameters: {'epochs': 350, 'lr': 0.0021731767864215995, 'weight_decay': 6.0082953927236985e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 5.038050459908515e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:22,721] Trial 66 finished with value: 0.7537747621536255 and parameters: {'epochs': 370, 'lr': 0.02132569282228145, 'weight_decay': 0.0029078285942650073, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 3.227849100215417e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:24,513] Trial 67 finished with value: 0.7520846128463745 and parameters: {'epochs': 407, 'lr': 0.0006623566388979775, 'weight_decay': 0.008729153626389626, 'optimizer': 'SGD', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 1.7228601921279355e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:26,827] Trial 68 finished with value: 0.7726447582244873 and parameters: {'epochs': 488, 'lr': 0.0033827213251202714, 'weight_decay': 0.00010821342109432349, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00014250377151564403}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:28,957] Trial 69 finished with value: 0.745871901512146 and parameters: {'epochs': 451, 'lr': 0.0009635727662867591, 'weight_decay': 3.993099713548922e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.09613987630175495}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:30,631] Trial 70 finished with value: 0.7656702995300293 and parameters: {'epochs': 324, 'lr': 0.0018998361468912804, 'weight_decay': 2.5669820368045595e-05, 'optimizer': 'AdamW', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0003240304719726849}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:32,804] Trial 71 finished with value: 0.7892742156982422 and parameters: {'epochs': 417, 'lr': 0.0011893154105001675, 'weight_decay': 4.987676878555705e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0016875482888597355}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:34,842] Trial 72 finished with value: 0.787772536277771 and parameters: {'epochs': 409, 'lr': 0.0011796252557306087, 'weight_decay': 4.642748957149605e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0009559687501161574}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:36,705] Trial 73 finished with value: 0.777829110622406 and parameters: {'epochs': 382, 'lr': 0.0016188998025015212, 'weight_decay': 1.3722533541819925e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0033804714193486807}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:38,926] Trial 74 finished with value: 0.7717430591583252 and parameters: {'epochs': 436, 'lr': 0.0023204636172015707, 'weight_decay': 0.0009490653172386357, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0017402917961022585}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:40,676] Trial 75 finished with value: 0.765709400177002 and parameters: {'epochs': 368, 'lr': 0.0003644188355685841, 'weight_decay': 0.00017183064989945024, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0046537904232281605}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:42,649] Trial 76 finished with value: 0.7604630589485168 and parameters: {'epochs': 391, 'lr': 0.06779385466658105, 'weight_decay': 3.0446962540057007e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 1.2677375362632513e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:44,619] Trial 77 finished with value: 0.7404780387878418 and parameters: {'epochs': 412, 'lr': 0.0008395358022192677, 'weight_decay': 0.0002469910168457471, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 2.403323137885327e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:46,643] Trial 78 finished with value: 0.785452663898468 and parameters: {'epochs': 429, 'lr': 0.0005746460913933115, 'weight_decay': 9.488130761410685e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00021367674785731003}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:48,730] Trial 79 finished with value: 0.7702193260192871 and parameters: {'epochs': 465, 'lr': 0.004495883974409786, 'weight_decay': 0.7690002237420884, 'optimizer': 'SGD', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 0.002556161344835215}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:50,328] Trial 80 finished with value: 0.7604573965072632 and parameters: {'epochs': 315, 'lr': 0.006435804334363307, 'weight_decay': 2.071938867490958e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.0008293230860746929}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:52,002] Trial 81 finished with value: 0.7996290326118469 and parameters: {'epochs': 349, 'lr': 0.0017323951697463945, 'weight_decay': 0.00018525512549794954, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0011241044655527462}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:53,692] Trial 82 finished with value: 0.789237380027771 and parameters: {'epochs': 344, 'lr': 0.0017929897264087268, 'weight_decay': 0.000122556424986549, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0011406005154960192}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:55,497] Trial 83 finished with value: 0.7908542156219482 and parameters: {'epochs': 378, 'lr': 0.002510708401320652, 'weight_decay': 6.332193898061935e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.001971531427099745}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:57,089] Trial 84 finished with value: 0.772223174571991 and parameters: {'epochs': 328, 'lr': 0.0013696295307815555, 'weight_decay': 0.00041662735561986833, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.00667669602915221}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:41:58,824] Trial 85 finished with value: 0.7835625410079956 and parameters: {'epochs': 346, 'lr': 0.0010528287599406389, 'weight_decay': 4.147435283923592e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0033152515818630655}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:00,584] Trial 86 finished with value: 0.7813800573348999 and parameters: {'epochs': 363, 'lr': 0.003261339457066958, 'weight_decay': 0.0001982451217753043, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 4.153762802785673e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:02,746] Trial 87 finished with value: 0.7563610076904297 and parameters: {'epochs': 444, 'lr': 0.0020975292902225286, 'weight_decay': 8.512510480280354e-05, 'optimizer': 'AdamW', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 5.51097589915064e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:04,519] Trial 88 finished with value: 0.7726630568504333 and parameters: {'epochs': 337, 'lr': 0.0028570076573342955, 'weight_decay': 0.3103864065698558, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 8.091721846240052e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:06,383] Trial 89 finished with value: 0.7877150774002075 and parameters: {'epochs': 398, 'lr': 0.0016993171585491464, 'weight_decay': 1.0135816181170147e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0005179773860752679}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:07,795] Trial 90 finished with value: 0.7828199863433838 and parameters: {'epochs': 273, 'lr': 0.0040444800410574374, 'weight_decay': 2.6044714665337133e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 2.8600415294234342e-05}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:09,509] Trial 91 finished with value: 0.7751442193984985 and parameters: {'epochs': 359, 'lr': 0.0013807459800657341, 'weight_decay': 0.0001676330066881226, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.012866955510698747}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:11,591] Trial 92 finished with value: 0.7841131687164307 and parameters: {'epochs': 424, 'lr': 0.0018889678953153868, 'weight_decay': 0.0002956762066694838, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0013941236168992215}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:13,419] Trial 93 finished with value: 0.7739517688751221 and parameters: {'epochs': 382, 'lr': 0.001998759720489851, 'weight_decay': 5.508815170852691e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0010361588867388877}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:15,239] Trial 94 finished with value: 0.7742833495140076 and parameters: {'epochs': 371, 'lr': 0.0024814523509627184, 'weight_decay': 0.00013398687726985125, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.008425627256774757}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:16,959] Trial 95 finished with value: 0.7718127369880676 and parameters: {'epochs': 355, 'lr': 0.0011909541826193673, 'weight_decay': 7.986971633442331e-05, 'optimizer': 'SGD', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 0.00012383508395853236}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:18,870] Trial 96 finished with value: 0.770719051361084 and parameters: {'epochs': 404, 'lr': 0.0009931610777017097, 'weight_decay': 1.6305584929413032e-05, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0005322044090011214}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:20,367] Trial 97 finished with value: 0.7671515941619873 and parameters: {'epochs': 312, 'lr': 0.001551171880993415, 'weight_decay': 0.0005004848223187708, 'optimizer': 'SGD', 'kernel_size': 2, 'loss_fn': 'bce', 'l1': 0.0008348215414545865}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:21,712] Trial 98 finished with value: 0.7366089224815369 and parameters: {'epochs': 296, 'lr': 0.0036236525025847995, 'weight_decay': 3.1312412041148815e-05, 'optimizer': 'SGD', 'kernel_size': 1, 'loss_fn': 'bce', 'l1': 0.01946512733676344}. Best is trial 47 with value: 0.8262251615524292.\n",
      "[I 2025-03-08 03:42:23,354] Trial 99 finished with value: 0.7520186901092529 and parameters: {'epochs': 333, 'lr': 0.000740975175198607, 'weight_decay': 0.00021233183184541984, 'optimizer': 'AdamW', 'kernel_size': 3, 'loss_fn': 'bce', 'l1': 2.1260599125997352e-05}. Best is trial 47 with value: 0.8262251615524292.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize the study by running a number of trials (e.g., 100 trials).\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Best Validation F1 Score: 0.8262\n",
      "  Hyperparameters:\n",
      "    epochs: 325\n",
      "    lr: 0.0003618543621266028\n",
      "    weight_decay: 1.979201053287094e-05\n",
      "    optimizer: SGD\n",
      "    kernel_size: 3\n",
      "    loss_fn: bce\n",
      "    l1: 0.0047670779365748895\n"
     ]
    }
   ],
   "source": [
    "# Print out the best trial.\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"  Best Validation F1 Score: {:.4f}\".format(best_trial.value))\n",
    "print(\"  Hyperparameters:\")\n",
    "for param_name, param_value in best_trial.params.items():\n",
    "    print(\"    {}: {}\".format(param_name, param_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
