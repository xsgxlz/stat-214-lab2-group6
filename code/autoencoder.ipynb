{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision\n",
    "from torchvision.models.efficientnet import MBConvConfig, FusedMBConvConfig\n",
    "\n",
    "sys.path.append(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling\")\n",
    "from preprocessing import to_NCHW, pad_to_384x384, standardize_images\n",
    "from autoencoder import EfficientNetEncoder, EfficientNetDecoder, AutoencoderConfig, masked_mse\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = np.load(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/data/array_data.npz\")\n",
    "unlabeled_images, unlabeled_masks, labeled_images, labeled_masks, labels = data[\"unlabeled_images\"], data[\"unlabeled_masks\"], data[\"labeled_images\"], data[\"labeled_masks\"], data[\"labels\"]\n",
    "\n",
    "unlabeled_images = pad_to_384x384(to_NCHW(unlabeled_images))\n",
    "unlabeled_masks = pad_to_384x384(unlabeled_masks)\n",
    "\n",
    "labeled_images = pad_to_384x384(to_NCHW(labeled_images))\n",
    "labeled_masks = pad_to_384x384(labeled_masks)\n",
    "labels = pad_to_384x384(labels)\n",
    "\n",
    "# Convert to tensors and move to GPU\n",
    "unlabeled_images = torch.tensor(unlabeled_images, dtype=torch.float32).to(device)  # [161, 8, 384, 384]\n",
    "unlabeled_masks = torch.tensor(unlabeled_masks, dtype=torch.bool).to(device)    # [161, 384, 384]\n",
    "\n",
    "labeled_images = torch.tensor(labeled_images, dtype=torch.float32).to(device)      # [3, 8, 384, 384]\n",
    "labeled_masks = torch.tensor(labeled_masks, dtype=torch.bool).to(device)        # [3, 384, 384]\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)                      # [3, 384, 384]\n",
    "\n",
    "\n",
    "# Standardize images\n",
    "unlabeled_images, std_channel, mean_channel = standardize_images(unlabeled_images, unlabeled_masks)\n",
    "labeled_images, _, _ = standardize_images(labeled_images, labeled_masks, std_channel, mean_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoencoderConfig([1, 1, 1], flip=True, rotate=True)\n"
     ]
    }
   ],
   "source": [
    "config = AutoencoderConfig(num_layers_block=[1, 1, 1], augmentation_flip=True, augmentation_rotate=True)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = []\n",
    "if config.augmentation_flip:\n",
    "    augmentation.append(torchvision.transforms.RandomHorizontalFlip(p=0.5))\n",
    "    augmentation.append(torchvision.transforms.RandomVerticalFlip(p=0.5))\n",
    "if config.augmentation_rotate:\n",
    "    augmentation.append(torchvision.transforms.RandomRotation(degrees=180, expand=True,\n",
    "                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR))\n",
    "    augmentation.append(torchvision.transforms.RandomCrop(size=384))\n",
    "augmentation = torchvision.transforms.Compose(augmentation)\n",
    "\n",
    "def apply_augment(images, masks, augmentation):\n",
    "    images_masks = torch.cat([masks.unsqueeze(1).float(), images], dim=1)\n",
    "    images_masks = [augmentation(image_mask) for image_mask in images_masks]\n",
    "    images_masks = torch.stack(images_masks)\n",
    "    return images_masks[:, 1:], images_masks[:, 0] > 0.5\n",
    "\n",
    "augment = lambda images, masks: apply_augment(images, masks, augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config = [\n",
    "    FusedMBConvConfig(1, 3, 1, 16, 16, config.num_layers_block[0]),  # 384x384x8 -> 384x384x16\n",
    "    FusedMBConvConfig(4, 3, 2, 16, 32, config.num_layers_block[1]),  # 384x384x16 -> 192x192x32\n",
    "    MBConvConfig(4, 3, 2, 32, 64, config.num_layers_block[2]),       # 192x192x32 -> 96x96x64\n",
    "]\n",
    "\n",
    "# Build encoder and decoder\n",
    "encoder = EfficientNetEncoder(\n",
    "    inverted_residual_setting=encoder_config,\n",
    "    dropout=0.1,\n",
    "    input_channels=8,\n",
    "    last_channel=64,\n",
    ")\n",
    "\n",
    "decoder = EfficientNetDecoder()\n",
    "\n",
    "autoencoder = nn.Sequential(encoder, decoder).train().to(device)\n",
    "#compiled_autoencoder = torch.compile(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20000\n",
    "ckpt = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 14000, 16000, 18000, 20000]\n",
    "initial_lr = 1e-3  # Moderate starting LR for AdamW\n",
    "weight_decay = 1e-2  # Regularization for small dataset\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(autoencoder.parameters(), lr=initial_lr, weight_decay=weight_decay)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)  # Decay to near-zero\n",
    "scaler = torch.amp.GradScaler(device, enabled=use_amp)\n",
    "\n",
    "losses = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def trainer(images, masks, model, augment, optimizer, scheduler, scaler, loss_fn):\n",
    "    with torch.inference_mode():\n",
    "        images, masks = augment(images, masks)\n",
    "    images, masks = images.clone(), masks.clone()\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    with torch.amp.autocast(device, enabled=use_amp):\n",
    "        reconstructions = model(images)\n",
    "        loss = loss_fn(images, masks, reconstructions)\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling/ckpt\"\n",
    "os.makedirs(f\"{ckpt_path}/{str(config)}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0] Graph break from `Tensor.item()`, consider setting:\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0]     torch._dynamo.config.capture_scalar_outputs = True\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0] or:\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0] to include these operations in the captured graph.\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0] \n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0] Graph break: from user code at:\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0]   File \"/jet/home/azhang19/.conda/envs/env_214/lib/python3.13/site-packages/torchvision/transforms/transforms.py\", line 1370, in forward\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0]     angle = self.get_params(self.degrees)\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0]   File \"/jet/home/azhang19/.conda/envs/env_214/lib/python3.13/site-packages/torchvision/transforms/transforms.py\", line 1352, in get_params\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0]     angle = float(torch.empty(1).uniform_(float(degrees[0]), float(degrees[1])).item())\n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0] \n",
      "W0308 04:34:44.316000 65585 site-packages/torch/_dynamo/variables/tensor.py:869] [8/0] \n",
      "W0308 04:34:59.626000 65585 site-packages/torch/_dynamo/convert_frame.py:906] [25/8] torch._dynamo hit config.cache_size_limit (8)\n",
      "W0308 04:34:59.626000 65585 site-packages/torch/_dynamo/convert_frame.py:906] [25/8]    function: 'torch_dynamo_resume_in_rotate_at_665' (/jet/home/azhang19/.conda/envs/env_214/lib/python3.13/site-packages/torchvision/transforms/_functional_tensor.py:665)\n",
      "W0308 04:34:59.626000 65585 site-packages/torch/_dynamo/convert_frame.py:906] [25/8]    last reason: 25/0: L['oh'] == 482                                              \n",
      "W0308 04:34:59.626000 65585 site-packages/torch/_dynamo/convert_frame.py:906] [25/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W0308 04:34:59.626000 65585 site-packages/torch/_dynamo/convert_frame.py:906] [25/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "W0308 04:35:10.325000 65585 site-packages/torch/_logging/_internal.py:1089] [38/0] Profiler function <class 'torch.autograd.profiler.record_function'> will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20000 - Loss: 2.2147 - Time: 30.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "('Grad tensors [\"L['self'].param_groups[0]['params'][0].grad\", \"L['self'].param_groups[0]['params'][1].grad\", \"L['self'].param_groups[0]['params'][2].grad\", \"L['self'].param_groups[0]['params'][3].grad\", \"L['self'].param_groups[0]['params'][4].grad\", \"L['self'].param_groups[0]['params'][5].grad\", \"L['self'].param_groups[0]['params'][6].grad\", \"L['self'].param_groups[0]['params'][7].grad\", \"L['self'].param_groups[0]['params'][8].grad\", \"L['self'].param_groups[0]['params'][9].grad\", \"L['self'].param_groups[0]['params'][10].grad\", \"L['self'].param_groups[0]['params'][11].grad\", \"L['self'].param_groups[0]['params'][12].grad\", \"L['self'].param_groups[0]['params'][13].grad\", \"L['self'].param_groups[0]['params'][14].grad\", \"L['self'].param_groups[0]['params'][15].grad\", \"L['self'].param_groups[0]['params'][16].grad\", \"L['self'].param_groups[0]['params'][17].grad\", \"L['self'].param_groups[0]['params'][18].grad\", \"L['self'].param_groups[0]['params'][19].grad\", \"L['self'].param_groups[0]['params'][20].grad\", \"L['self'].param_groups[0]['params'][21].grad\", \"L['self'].param_groups[0]['params'][22].grad\", \"L['self'].param_groups[0]['params'][23].grad\", \"L['self'].param_groups[0]['params'][24].grad\", \"L['self'].param_groups[0]['params'][25].grad\", \"L['self'].param_groups[0]['params'][26].grad\", \"L['self'].param_groups[0]['params'][27].grad\", \"L['self'].param_groups[0]['params'][28].grad\", \"L['self'].param_groups[0]['params'][29].grad\", \"L['self'].param_groups[0]['params'][30].grad\", \"L['self'].param_groups[0]['params'][31].grad\", \"L['self'].param_groups[0]['params'][32].grad\", \"L['self'].param_groups[0]['params'][33].grad\", \"L['self'].param_groups[0]['params'][34].grad\", \"L['self'].param_groups[0]['params'][35].grad\", \"L['self'].param_groups[0]['params'][36].grad\", \"L['self'].param_groups[0]['params'][37].grad\", \"L['self'].param_groups[0]['params'][38].grad\", \"L['self'].param_groups[0]['params'][39].grad\", \"L['self'].param_groups[0]['params'][40].grad\", \"L['self'].param_groups[0]['params'][41].grad\", \"L['self'].param_groups[0]['params'][42].grad\", \"L['self'].param_groups[0]['params'][43].grad\"] will be copied during cudagraphs execution.If using cudagraphs and the grad tensor addresses will be the same across runs, use torch._dynamo.decorators.mark_static_address to elide this copy.',)\n",
      "('Grad tensors [\"L['self'].param_groups[0]['params'][0].grad\", \"L['self'].param_groups[0]['params'][1].grad\", \"L['self'].param_groups[0]['params'][2].grad\", \"L['self'].param_groups[0]['params'][3].grad\", \"L['self'].param_groups[0]['params'][4].grad\", \"L['self'].param_groups[0]['params'][5].grad\", \"L['self'].param_groups[0]['params'][6].grad\", \"L['self'].param_groups[0]['params'][7].grad\", \"L['self'].param_groups[0]['params'][8].grad\", \"L['self'].param_groups[0]['params'][9].grad\", \"L['self'].param_groups[0]['params'][10].grad\", \"L['self'].param_groups[0]['params'][11].grad\", \"L['self'].param_groups[0]['params'][12].grad\", \"L['self'].param_groups[0]['params'][13].grad\", \"L['self'].param_groups[0]['params'][14].grad\", \"L['self'].param_groups[0]['params'][15].grad\", \"L['self'].param_groups[0]['params'][16].grad\", \"L['self'].param_groups[0]['params'][17].grad\", \"L['self'].param_groups[0]['params'][18].grad\", \"L['self'].param_groups[0]['params'][19].grad\", \"L['self'].param_groups[0]['params'][20].grad\", \"L['self'].param_groups[0]['params'][21].grad\", \"L['self'].param_groups[0]['params'][22].grad\", \"L['self'].param_groups[0]['params'][23].grad\", \"L['self'].param_groups[0]['params'][24].grad\", \"L['self'].param_groups[0]['params'][25].grad\", \"L['self'].param_groups[0]['params'][26].grad\", \"L['self'].param_groups[0]['params'][27].grad\", \"L['self'].param_groups[0]['params'][28].grad\", \"L['self'].param_groups[0]['params'][29].grad\", \"L['self'].param_groups[0]['params'][30].grad\", \"L['self'].param_groups[0]['params'][31].grad\", \"L['self'].param_groups[0]['params'][32].grad\", \"L['self'].param_groups[0]['params'][33].grad\", \"L['self'].param_groups[0]['params'][34].grad\", \"L['self'].param_groups[0]['params'][35].grad\", \"L['self'].param_groups[0]['params'][36].grad\", \"L['self'].param_groups[0]['params'][37].grad\", \"L['self'].param_groups[0]['params'][38].grad\", \"L['self'].param_groups[0]['params'][39].grad\", \"L['self'].param_groups[0]['params'][40].grad\", \"L['self'].param_groups[0]['params'][41].grad\", \"L['self'].param_groups[0]['params'][42].grad\", \"L['self'].param_groups[0]['params'][43].grad\"] will be copied during cudagraphs execution.If using cudagraphs and the grad tensor addresses will be the same across runs, use torch._dynamo.decorators.mark_static_address to elide this copy.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20000 - Loss: 1.9491 - Time: 2.87s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "('Grad tensors [\"L['self'].param_groups[0]['params'][0].grad\", \"L['self'].param_groups[0]['params'][1].grad\", \"L['self'].param_groups[0]['params'][2].grad\", \"L['self'].param_groups[0]['params'][3].grad\", \"L['self'].param_groups[0]['params'][4].grad\", \"L['self'].param_groups[0]['params'][5].grad\", \"L['self'].param_groups[0]['params'][6].grad\", \"L['self'].param_groups[0]['params'][7].grad\", \"L['self'].param_groups[0]['params'][8].grad\", \"L['self'].param_groups[0]['params'][9].grad\", \"L['self'].param_groups[0]['params'][10].grad\", \"L['self'].param_groups[0]['params'][11].grad\", \"L['self'].param_groups[0]['params'][12].grad\", \"L['self'].param_groups[0]['params'][13].grad\", \"L['self'].param_groups[0]['params'][14].grad\", \"L['self'].param_groups[0]['params'][15].grad\", \"L['self'].param_groups[0]['params'][16].grad\", \"L['self'].param_groups[0]['params'][17].grad\", \"L['self'].param_groups[0]['params'][18].grad\", \"L['self'].param_groups[0]['params'][19].grad\", \"L['self'].param_groups[0]['params'][20].grad\", \"L['self'].param_groups[0]['params'][21].grad\", \"L['self'].param_groups[0]['params'][22].grad\", \"L['self'].param_groups[0]['params'][23].grad\", \"L['self'].param_groups[0]['params'][24].grad\", \"L['self'].param_groups[0]['params'][25].grad\", \"L['self'].param_groups[0]['params'][26].grad\", \"L['self'].param_groups[0]['params'][27].grad\", \"L['self'].param_groups[0]['params'][28].grad\", \"L['self'].param_groups[0]['params'][29].grad\", \"L['self'].param_groups[0]['params'][30].grad\", \"L['self'].param_groups[0]['params'][31].grad\", \"L['self'].param_groups[0]['params'][32].grad\", \"L['self'].param_groups[0]['params'][33].grad\", \"L['self'].param_groups[0]['params'][34].grad\", \"L['self'].param_groups[0]['params'][35].grad\", \"L['self'].param_groups[0]['params'][36].grad\", \"L['self'].param_groups[0]['params'][37].grad\", \"L['self'].param_groups[0]['params'][38].grad\", \"L['self'].param_groups[0]['params'][39].grad\", \"L['self'].param_groups[0]['params'][40].grad\", \"L['self'].param_groups[0]['params'][41].grad\", \"L['self'].param_groups[0]['params'][42].grad\", \"L['self'].param_groups[0]['params'][43].grad\"] will be copied during cudagraphs execution.If using cudagraphs and the grad tensor addresses will be the same across runs, use torch._dynamo.decorators.mark_static_address to elide this copy.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20000 - Loss: 1.6571 - Time: 1.56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "('Grad tensors [\"L['self'].param_groups[0]['params'][0].grad\", \"L['self'].param_groups[0]['params'][1].grad\", \"L['self'].param_groups[0]['params'][2].grad\", \"L['self'].param_groups[0]['params'][3].grad\", \"L['self'].param_groups[0]['params'][4].grad\", \"L['self'].param_groups[0]['params'][5].grad\", \"L['self'].param_groups[0]['params'][6].grad\", \"L['self'].param_groups[0]['params'][7].grad\", \"L['self'].param_groups[0]['params'][8].grad\", \"L['self'].param_groups[0]['params'][9].grad\", \"L['self'].param_groups[0]['params'][10].grad\", \"L['self'].param_groups[0]['params'][11].grad\", \"L['self'].param_groups[0]['params'][12].grad\", \"L['self'].param_groups[0]['params'][13].grad\", \"L['self'].param_groups[0]['params'][14].grad\", \"L['self'].param_groups[0]['params'][15].grad\", \"L['self'].param_groups[0]['params'][16].grad\", \"L['self'].param_groups[0]['params'][17].grad\", \"L['self'].param_groups[0]['params'][18].grad\", \"L['self'].param_groups[0]['params'][19].grad\", \"L['self'].param_groups[0]['params'][20].grad\", \"L['self'].param_groups[0]['params'][21].grad\", \"L['self'].param_groups[0]['params'][22].grad\", \"L['self'].param_groups[0]['params'][23].grad\", \"L['self'].param_groups[0]['params'][24].grad\", \"L['self'].param_groups[0]['params'][25].grad\", \"L['self'].param_groups[0]['params'][26].grad\", \"L['self'].param_groups[0]['params'][27].grad\", \"L['self'].param_groups[0]['params'][28].grad\", \"L['self'].param_groups[0]['params'][29].grad\", \"L['self'].param_groups[0]['params'][30].grad\", \"L['self'].param_groups[0]['params'][31].grad\", \"L['self'].param_groups[0]['params'][32].grad\", \"L['self'].param_groups[0]['params'][33].grad\", \"L['self'].param_groups[0]['params'][34].grad\", \"L['self'].param_groups[0]['params'][35].grad\", \"L['self'].param_groups[0]['params'][36].grad\", \"L['self'].param_groups[0]['params'][37].grad\", \"L['self'].param_groups[0]['params'][38].grad\", \"L['self'].param_groups[0]['params'][39].grad\", \"L['self'].param_groups[0]['params'][40].grad\", \"L['self'].param_groups[0]['params'][41].grad\", \"L['self'].param_groups[0]['params'][42].grad\", \"L['self'].param_groups[0]['params'][43].grad\"] will be copied during cudagraphs execution.If using cudagraphs and the grad tensor addresses will be the same across runs, use torch._dynamo.decorators.mark_static_address to elide this copy.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20000 - Loss: 1.3463 - Time: 1.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "('Grad tensors [\"L['self'].param_groups[0]['params'][0].grad\", \"L['self'].param_groups[0]['params'][1].grad\", \"L['self'].param_groups[0]['params'][2].grad\", \"L['self'].param_groups[0]['params'][3].grad\", \"L['self'].param_groups[0]['params'][4].grad\", \"L['self'].param_groups[0]['params'][5].grad\", \"L['self'].param_groups[0]['params'][6].grad\", \"L['self'].param_groups[0]['params'][7].grad\", \"L['self'].param_groups[0]['params'][8].grad\", \"L['self'].param_groups[0]['params'][9].grad\", \"L['self'].param_groups[0]['params'][10].grad\", \"L['self'].param_groups[0]['params'][11].grad\", \"L['self'].param_groups[0]['params'][12].grad\", \"L['self'].param_groups[0]['params'][13].grad\", \"L['self'].param_groups[0]['params'][14].grad\", \"L['self'].param_groups[0]['params'][15].grad\", \"L['self'].param_groups[0]['params'][16].grad\", \"L['self'].param_groups[0]['params'][17].grad\", \"L['self'].param_groups[0]['params'][18].grad\", \"L['self'].param_groups[0]['params'][19].grad\", \"L['self'].param_groups[0]['params'][20].grad\", \"L['self'].param_groups[0]['params'][21].grad\", \"L['self'].param_groups[0]['params'][22].grad\", \"L['self'].param_groups[0]['params'][23].grad\", \"L['self'].param_groups[0]['params'][24].grad\", \"L['self'].param_groups[0]['params'][25].grad\", \"L['self'].param_groups[0]['params'][26].grad\", \"L['self'].param_groups[0]['params'][27].grad\", \"L['self'].param_groups[0]['params'][28].grad\", \"L['self'].param_groups[0]['params'][29].grad\", \"L['self'].param_groups[0]['params'][30].grad\", \"L['self'].param_groups[0]['params'][31].grad\", \"L['self'].param_groups[0]['params'][32].grad\", \"L['self'].param_groups[0]['params'][33].grad\", \"L['self'].param_groups[0]['params'][34].grad\", \"L['self'].param_groups[0]['params'][35].grad\", \"L['self'].param_groups[0]['params'][36].grad\", \"L['self'].param_groups[0]['params'][37].grad\", \"L['self'].param_groups[0]['params'][38].grad\", \"L['self'].param_groups[0]['params'][39].grad\", \"L['self'].param_groups[0]['params'][40].grad\", \"L['self'].param_groups[0]['params'][41].grad\", \"L['self'].param_groups[0]['params'][42].grad\", \"L['self'].param_groups[0]['params'][43].grad\"] will be copied during cudagraphs execution.If using cudagraphs and the grad tensor addresses will be the same across runs, use torch._dynamo.decorators.mark_static_address to elide this copy.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20000 - Loss: 1.1017 - Time: 1.86s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "('Grad tensors [\"L['self'].param_groups[0]['params'][0].grad\", \"L['self'].param_groups[0]['params'][1].grad\", \"L['self'].param_groups[0]['params'][2].grad\", \"L['self'].param_groups[0]['params'][3].grad\", \"L['self'].param_groups[0]['params'][4].grad\", \"L['self'].param_groups[0]['params'][5].grad\", \"L['self'].param_groups[0]['params'][6].grad\", \"L['self'].param_groups[0]['params'][7].grad\", \"L['self'].param_groups[0]['params'][8].grad\", \"L['self'].param_groups[0]['params'][9].grad\", \"L['self'].param_groups[0]['params'][10].grad\", \"L['self'].param_groups[0]['params'][11].grad\", \"L['self'].param_groups[0]['params'][12].grad\", \"L['self'].param_groups[0]['params'][13].grad\", \"L['self'].param_groups[0]['params'][14].grad\", \"L['self'].param_groups[0]['params'][15].grad\", \"L['self'].param_groups[0]['params'][16].grad\", \"L['self'].param_groups[0]['params'][17].grad\", \"L['self'].param_groups[0]['params'][18].grad\", \"L['self'].param_groups[0]['params'][19].grad\", \"L['self'].param_groups[0]['params'][20].grad\", \"L['self'].param_groups[0]['params'][21].grad\", \"L['self'].param_groups[0]['params'][22].grad\", \"L['self'].param_groups[0]['params'][23].grad\", \"L['self'].param_groups[0]['params'][24].grad\", \"L['self'].param_groups[0]['params'][25].grad\", \"L['self'].param_groups[0]['params'][26].grad\", \"L['self'].param_groups[0]['params'][27].grad\", \"L['self'].param_groups[0]['params'][28].grad\", \"L['self'].param_groups[0]['params'][29].grad\", \"L['self'].param_groups[0]['params'][30].grad\", \"L['self'].param_groups[0]['params'][31].grad\", \"L['self'].param_groups[0]['params'][32].grad\", \"L['self'].param_groups[0]['params'][33].grad\", \"L['self'].param_groups[0]['params'][34].grad\", \"L['self'].param_groups[0]['params'][35].grad\", \"L['self'].param_groups[0]['params'][36].grad\", \"L['self'].param_groups[0]['params'][37].grad\", \"L['self'].param_groups[0]['params'][38].grad\", \"L['self'].param_groups[0]['params'][39].grad\", \"L['self'].param_groups[0]['params'][40].grad\", \"L['self'].param_groups[0]['params'][41].grad\", \"L['self'].param_groups[0]['params'][42].grad\", \"L['self'].param_groups[0]['params'][43].grad\"] will be copied during cudagraphs execution.If using cudagraphs and the grad tensor addresses will be the same across runs, use torch._dynamo.decorators.mark_static_address to elide this copy.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20000 - Loss: 0.9204 - Time: 1.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "('Grad tensors [\"L['self'].param_groups[0]['params'][0].grad\", \"L['self'].param_groups[0]['params'][1].grad\", \"L['self'].param_groups[0]['params'][2].grad\", \"L['self'].param_groups[0]['params'][3].grad\", \"L['self'].param_groups[0]['params'][4].grad\", \"L['self'].param_groups[0]['params'][5].grad\", \"L['self'].param_groups[0]['params'][6].grad\", \"L['self'].param_groups[0]['params'][7].grad\", \"L['self'].param_groups[0]['params'][8].grad\", \"L['self'].param_groups[0]['params'][9].grad\", \"L['self'].param_groups[0]['params'][10].grad\", \"L['self'].param_groups[0]['params'][11].grad\", \"L['self'].param_groups[0]['params'][12].grad\", \"L['self'].param_groups[0]['params'][13].grad\", \"L['self'].param_groups[0]['params'][14].grad\", \"L['self'].param_groups[0]['params'][15].grad\", \"L['self'].param_groups[0]['params'][16].grad\", \"L['self'].param_groups[0]['params'][17].grad\", \"L['self'].param_groups[0]['params'][18].grad\", \"L['self'].param_groups[0]['params'][19].grad\", \"L['self'].param_groups[0]['params'][20].grad\", \"L['self'].param_groups[0]['params'][21].grad\", \"L['self'].param_groups[0]['params'][22].grad\", \"L['self'].param_groups[0]['params'][23].grad\", \"L['self'].param_groups[0]['params'][24].grad\", \"L['self'].param_groups[0]['params'][25].grad\", \"L['self'].param_groups[0]['params'][26].grad\", \"L['self'].param_groups[0]['params'][27].grad\", \"L['self'].param_groups[0]['params'][28].grad\", \"L['self'].param_groups[0]['params'][29].grad\", \"L['self'].param_groups[0]['params'][30].grad\", \"L['self'].param_groups[0]['params'][31].grad\", \"L['self'].param_groups[0]['params'][32].grad\", \"L['self'].param_groups[0]['params'][33].grad\", \"L['self'].param_groups[0]['params'][34].grad\", \"L['self'].param_groups[0]['params'][35].grad\", \"L['self'].param_groups[0]['params'][36].grad\", \"L['self'].param_groups[0]['params'][37].grad\", \"L['self'].param_groups[0]['params'][38].grad\", \"L['self'].param_groups[0]['params'][39].grad\", \"L['self'].param_groups[0]['params'][40].grad\", \"L['self'].param_groups[0]['params'][41].grad\", \"L['self'].param_groups[0]['params'][42].grad\", \"L['self'].param_groups[0]['params'][43].grad\"] will be copied during cudagraphs execution.If using cudagraphs and the grad tensor addresses will be the same across runs, use torch._dynamo.decorators.mark_static_address to elide this copy.',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20000 - Loss: 0.8153 - Time: 1.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "('Grad tensors [\"L['self'].param_groups[0]['params'][0].grad\", \"L['self'].param_groups[0]['params'][1].grad\", \"L['self'].param_groups[0]['params'][2].grad\", \"L['self'].param_groups[0]['params'][3].grad\", \"L['self'].param_groups[0]['params'][4].grad\", \"L['self'].param_groups[0]['params'][5].grad\", \"L['self'].param_groups[0]['params'][6].grad\", \"L['self'].param_groups[0]['params'][7].grad\", \"L['self'].param_groups[0]['params'][8].grad\", \"L['self'].param_groups[0]['params'][9].grad\", \"L['self'].param_groups[0]['params'][10].grad\", \"L['self'].param_groups[0]['params'][11].grad\", \"L['self'].param_groups[0]['params'][12].grad\", \"L['self'].param_groups[0]['params'][13].grad\", \"L['self'].param_groups[0]['params'][14].grad\", \"L['self'].param_groups[0]['params'][15].grad\", \"L['self'].param_groups[0]['params'][16].grad\", \"L['self'].param_groups[0]['params'][17].grad\", \"L['self'].param_groups[0]['params'][18].grad\", \"L['self'].param_groups[0]['params'][19].grad\", \"L['self'].param_groups[0]['params'][20].grad\", \"L['self'].param_groups[0]['params'][21].grad\", \"L['self'].param_groups[0]['params'][22].grad\", \"L['self'].param_groups[0]['params'][23].grad\", \"L['self'].param_groups[0]['params'][24].grad\", \"L['self'].param_groups[0]['params'][25].grad\", \"L['self'].param_groups[0]['params'][26].grad\", \"L['self'].param_groups[0]['params'][27].grad\", \"L['self'].param_groups[0]['params'][28].grad\", \"L['self'].param_groups[0]['params'][29].grad\", \"L['self'].param_groups[0]['params'][30].grad\", \"L['self'].param_groups[0]['params'][31].grad\", \"L['self'].param_groups[0]['params'][32].grad\", \"L['self'].param_groups[0]['params'][33].grad\", \"L['self'].param_groups[0]['params'][34].grad\", \"L['self'].param_groups[0]['params'][35].grad\", \"L['self'].param_groups[0]['params'][36].grad\", \"L['self'].param_groups[0]['params'][37].grad\", \"L['self'].param_groups[0]['params'][38].grad\", \"L['self'].param_groups[0]['params'][39].grad\", \"L['self'].param_groups[0]['params'][40].grad\", \"L['self'].param_groups[0]['params'][41].grad\", \"L['self'].param_groups[0]['params'][42].grad\", \"L['self'].param_groups[0]['params'][43].grad\"] will be copied during cudagraphs execution.If using cudagraphs and the grad tensor addresses will be the same across runs, use torch._dynamo.decorators.mark_static_address to elide this copy.',)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m      2\u001b[39m     t = time.perf_counter()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     loss = \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43munlabeled_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlabeled_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked_mse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     losses[epoch] = loss.item()\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m epoch + \u001b[32m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ckpt:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/eval_frame.py:574\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    570\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    571\u001b[39m )\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    576\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    577\u001b[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[32m    578\u001b[39m         saved_dynamic_layer_stack_depth\n\u001b[32m    579\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 152\u001b[39m, in \u001b[36mtrainer\u001b[39m\u001b[34m(images, masks, model, augment, optimizer, scheduler, scaler, loss_fn)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtorch_dynamo_resume_in_trainer_at_4\u001b[39m\u001b[34m(___stack0, ___stack1, images, masks, model, optimizer, scheduler, scaler, loss_fn)\u001b[39m\n\u001b[32m      5\u001b[39m images, masks = images.clone(), masks.clone()\n\u001b[32m      6\u001b[39m model.train()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(device, enabled=use_amp):\n\u001b[32m     10\u001b[39m     reconstructions = model(images)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 152\u001b[39m, in \u001b[36mtorch_dynamo_resume_in_trainer_at_7\u001b[39m\u001b[34m(___stack0, images, masks, model, optimizer, scheduler, scaler, loss_fn)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtorch_dynamo_resume_in_trainer_at_11\u001b[39m\u001b[34m(___stack0, ___stack1, model, optimizer, scheduler, scaler)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(device, enabled=use_amp):\n\u001b[32m     10\u001b[39m     reconstructions = model(images)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     loss = loss_fn(images, masks, reconstructions)\n\u001b[32m     13\u001b[39m scaler.scale(loss).backward()\n\u001b[32m     14\u001b[39m scaler.unscale_(optimizer)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtorch_dynamo_resume_in_trainer_at_13\u001b[39m\u001b[34m(___stack0, model, optimizer, scheduler, scaler, loss)\u001b[39m\n\u001b[32m     10\u001b[39m     reconstructions = model(images)\n\u001b[32m     11\u001b[39m     loss = loss_fn(images, masks, reconstructions)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m scaler.scale(loss).backward()\n\u001b[32m     14\u001b[39m scaler.unscale_(optimizer)\n\u001b[32m     15\u001b[39m nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtorch_dynamo_resume_in_trainer_at_13\u001b[39m\u001b[34m(___stack0, model, optimizer, scheduler, scaler, loss)\u001b[39m\n\u001b[32m     10\u001b[39m     reconstructions = model(images)\n\u001b[32m     11\u001b[39m     loss = loss_fn(images, masks, reconstructions)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m scaler.scale(loss).backward()\n\u001b[32m     14\u001b[39m scaler.unscale_(optimizer)\n\u001b[32m     15\u001b[39m nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtorch_dynamo_resume_in_trainer_at_14\u001b[39m\u001b[34m(___stack0, model, optimizer, scheduler, scaler, loss)\u001b[39m\n\u001b[32m     11\u001b[39m     loss = loss_fn(images, masks, reconstructions)\n\u001b[32m     13\u001b[39m scaler.scale(loss).backward()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m scaler.unscale_(optimizer)\n\u001b[32m     15\u001b[39m nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m     16\u001b[39m scaler.step(optimizer)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtorch_dynamo_resume_in_trainer_at_15\u001b[39m\u001b[34m(___stack0, optimizer, scheduler, scaler, loss)\u001b[39m\n\u001b[32m     13\u001b[39m scaler.scale(loss).backward()\n\u001b[32m     14\u001b[39m scaler.unscale_(optimizer)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m     16\u001b[39m scaler.step(optimizer)\n\u001b[32m     17\u001b[39m scaler.update()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/amp/grad_scaler.py:457\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    454\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    455\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/amp/grad_scaler.py:352\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    350\u001b[39m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     retval = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/optim/lr_scheduler.py:140\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    138\u001b[39m opt = opt_ref()\n\u001b[32m    139\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/optim/optimizer.py:493\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    489\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    490\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    491\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    496\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     93\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:1380\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1374\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1375\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1376\u001b[39m             )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1379\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:1164\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1162\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:547\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    544\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:986\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m    984\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m    989\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    995\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m    996\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m    997\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:715\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    713\u001b[39m     stack.enter_context(torch._dynamo.callback_handler.install_callbacks())\n\u001b[32m    714\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_utils_internal.py:95\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] = skip + \u001b[32m1\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     98\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     99\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:750\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    748\u001b[39m CompileContext.get().attempt = attempt\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/bytecode_transformation.py:1361\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1358\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1359\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:231\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m exit_stack.enter_context(torch_function_mode_stack_state_mgr)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    233\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/convert_frame.py:662\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    661\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    664\u001b[39m     speculation_log.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:2868\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2867\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2868\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:1052\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1053\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:962\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:659\u001b[39m, in \u001b[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation.reason)\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[32m    661\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generic_context_manager_depth > \u001b[32m0\u001b[39m:\n\u001b[32m    662\u001b[39m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[32m    663\u001b[39m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:2341\u001b[39m, in \u001b[36mInstructionTranslatorBase.CALL\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2339\u001b[39m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push=\u001b[32m1\u001b[39m)\n\u001b[32m   2340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m2341\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:2335\u001b[39m, in \u001b[36mInstructionTranslatorBase._call\u001b[39m\u001b[34m(self, inst, call_kw)\u001b[39m\n\u001b[32m   2330\u001b[39m     kwargs = {}\n\u001b[32m   2332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2333\u001b[39m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[32m   2334\u001b[39m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2335\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2336\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2337\u001b[39m     \u001b[38;5;28mself\u001b[39m.kw_names = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/symbolic_convert.py:897\u001b[39m, in \u001b[36mInstructionTranslatorBase.call_function\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m    895\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[38;5;28mself\u001b[39m.push(\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/variables/misc.py:1022\u001b[39m, in \u001b[36mGetAttrVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_function\u001b[39m(\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1018\u001b[39m     tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1019\u001b[39m     args: \u001b[33m\"\u001b[39m\u001b[33mList[VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1020\u001b[39m     kwargs: \u001b[33m\"\u001b[39m\u001b[33mDict[str, VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1021\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mVariableTracker\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/variables/optimizer.py:97\u001b[39m, in \u001b[36mOptimizerVariable.call_method\u001b[39m\u001b[34m(self, tx, name, args, kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m ret_val = \u001b[38;5;28mself\u001b[39m.value._init_group(*py_args, **py_kwargs)\n\u001b[32m     96\u001b[39m \u001b[38;5;28mself\u001b[39m.map_sources_and_install_guards(tx)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate_list_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# stash a weak_ptr to optimizer to invalidate code\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# if the optimizer object dies\u001b[39;00m\n\u001b[32m    100\u001b[39m mangled_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m__optimizer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m.value)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/variables/optimizer.py:364\u001b[39m, in \u001b[36mOptimizerVariable.update_list_args\u001b[39m\u001b[34m(self, tx, args, kwargs, py_args, py_kwargs)\u001b[39m\n\u001b[32m    362\u001b[39m tx.output.side_effects.mutation(arg)\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, torch.Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     arg.items.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrap_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    366\u001b[39m     source = arg.source \u001b[38;5;129;01mand\u001b[39;00m GetItemSource(arg.source, i)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/variables/optimizer.py:339\u001b[39m, in \u001b[36mOptimizerVariable.wrap_tensor\u001b[39m\u001b[34m(self, tx, tensor_value)\u001b[39m\n\u001b[32m    337\u001b[39m     mark_static_address(tensor_value)\n\u001b[32m    338\u001b[39m     source = \u001b[38;5;28mself\u001b[39m.tensor_to_source[tensor_value]\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[38;5;28mself\u001b[39m.static_tensor_names.add(\u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodule_key_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m tensor_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.grad_to_source:\n\u001b[32m    341\u001b[39m     source = \u001b[38;5;28mself\u001b[39m.grad_to_source[tensor_value]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/_dynamo/output_graph.py:716\u001b[39m, in \u001b[36mOutputGraph.module_key_name\u001b[39m\u001b[34m(*names)\u001b[39m\n\u001b[32m    713\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodule_key_name\u001b[39m(*names):\n\u001b[32m    715\u001b[39m     \u001b[38;5;66;03m# create a new unique name\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m     name = \u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m     \u001b[38;5;66;03m# Strip the guard lookup L/G access\u001b[39;00m\n\u001b[32m    718\u001b[39m     name = re.sub(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m^[GL]\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m[\u001b[39m\u001b[33m'\u001b[39m\u001b[33m?(.*?)\u001b[39m\u001b[33m'\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m]$\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/reprlib.py:21\u001b[39m, in \u001b[36mrecursive_repr.<locals>.decorating_function.<locals>.wrapper\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     19\u001b[39m repr_running.add(key)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     result = \u001b[43muser_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     23\u001b[39m     repr_running.discard(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:9\u001b[39m, in \u001b[36m__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/reprlib.py:21\u001b[39m, in \u001b[36mrecursive_repr.<locals>.decorating_function.<locals>.wrapper\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     19\u001b[39m repr_running.add(key)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     result = \u001b[43muser_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     23\u001b[39m     repr_running.discard(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:9\u001b[39m, in \u001b[36m__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/env_214/lib/python3.13/reprlib.py:21\u001b[39m, in \u001b[36mrecursive_repr.<locals>.decorating_function.<locals>.wrapper\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     19\u001b[39m repr_running.add(key)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     result = \u001b[43muser_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     23\u001b[39m     repr_running.discard(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:9\u001b[39m, in \u001b[36m__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    t = time.perf_counter()\n",
    "    loss = trainer(unlabeled_images, unlabeled_masks, autoencoder, augment, optimizer, scheduler, scaler, masked_mse)\n",
    "    losses[epoch] = loss.item()\n",
    "    if epoch + 1 in ckpt:\n",
    "        torch.save(autoencoder.state_dict(), f\"{ckpt_path}/{str(config)}/autoencoder_{epoch + 1}.pth\")\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {loss:.4f} - Time: {time.perf_counter() - t:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
