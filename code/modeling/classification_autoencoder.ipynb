{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.efficientnet import MBConvConfig, FusedMBConvConfig\n",
    "\n",
    "import optuna\n",
    "\n",
    "sys.path.append(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling\")\n",
    "from preprocessing import to_NCHW, pad_to_384x384, standardize_images\n",
    "from autoencoder import EfficientNetEncoder, EfficientNetDecoder, AutoencoderConfig\n",
    "from classification import train_and_validate\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = np.load(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/data/array_data.npz\")\n",
    "unlabeled_images, unlabeled_masks, labeled_images, labeled_masks, labels = data[\"unlabeled_images\"], data[\"unlabeled_masks\"], data[\"labeled_images\"], data[\"labeled_masks\"], data[\"labels\"]\n",
    "\n",
    "unlabeled_images = pad_to_384x384(to_NCHW(unlabeled_images))\n",
    "unlabeled_masks = pad_to_384x384(unlabeled_masks)\n",
    "\n",
    "labeled_images = pad_to_384x384(to_NCHW(labeled_images))\n",
    "labeled_masks = pad_to_384x384(labeled_masks)\n",
    "labels = pad_to_384x384(labels)\n",
    "\n",
    "# Convert to tensors and move to GPU\n",
    "unlabeled_images = torch.tensor(unlabeled_images, dtype=torch.float32).to(device)  # [161, 8, 384, 384]\n",
    "unlabeled_masks = torch.tensor(unlabeled_masks, dtype=torch.bool).to(device)    # [161, 384, 384]\n",
    "\n",
    "labeled_images = torch.tensor(labeled_images, dtype=torch.float32).to(device)      # [3, 8, 384, 384]\n",
    "labeled_masks = torch.tensor(labeled_masks, dtype=torch.bool).to(device)        # [3, 384, 384]\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)                      # [3, 384, 384]\n",
    "\n",
    "\n",
    "# Standardize images\n",
    "unlabeled_images, std_channel, mean_channel = standardize_images(unlabeled_images, unlabeled_masks)\n",
    "labeled_images, _, _ = standardize_images(labeled_images, labeled_masks, std_channel, mean_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and extract features\n",
    "ckpt_path = \"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling/ckpt\"\n",
    "saved_epoch = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 15000, 20000, 25000, 30000, 35000, 40000]\n",
    "\n",
    "all_features = torch.zeros((2, 2, 2, 2, 2, len(saved_epoch), 3, 64, 384, 384)).to(device)\n",
    "\n",
    "num_layers_per_block = [1, 2]\n",
    "augementation = [True, False]\n",
    "for block1, block2, block3, flip, rotate in itertools.product(*[num_layers_per_block] * 3,*[augementation] * 2):\n",
    "    config = AutoencoderConfig(\n",
    "        num_layers_block=[block1, block2, block3],\n",
    "        augmentation_flip=flip,\n",
    "        augmentation_rotate=rotate\n",
    "    )\n",
    "    encoder_config = [\n",
    "        FusedMBConvConfig(1, 3, 1, 16, 16, config.num_layers_block[0]),  # 384x384x8 -> 384x384x16\n",
    "        FusedMBConvConfig(4, 3, 2, 16, 32, config.num_layers_block[1]),  # 384x384x16 -> 192x192x32\n",
    "        MBConvConfig(4, 3, 2, 32, 64, config.num_layers_block[2]),       # 192x192x32 -> 96x96x64\n",
    "    ]\n",
    "\n",
    "    encoder = EfficientNetEncoder(\n",
    "        inverted_residual_setting=encoder_config,\n",
    "        dropout=0.1,\n",
    "        input_channels=8,\n",
    "        last_channel=64,\n",
    "    )\n",
    "\n",
    "    decoder = EfficientNetDecoder()\n",
    "    autoencoder = nn.Sequential(encoder, decoder).train().to(device)\n",
    "\n",
    "    folder_path = os.path.join(ckpt_path, str(config))\n",
    "    \n",
    "    for i, epoch in enumerate(saved_epoch):\n",
    "        autoencoder.load_state_dict(torch.load(os.path.join(folder_path, f\"autoencoder_{epoch}.pth\")))\n",
    "        autoencoder.eval()\n",
    "        with torch.inference_mode():\n",
    "            encoder = autoencoder[0]\n",
    "            features = encoder(labeled_images)\n",
    "            features = nn.functional.interpolate(features, size=384, mode=\"bicubic\", antialias=True)\n",
    "            all_features[block1-1, block2-1, block3-1, int(flip), int(rotate), i] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters with updated API calls\n",
    "    epochs = trial.suggest_int(\"epochs\", 0, 800)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"SGD\", \"AdamW\"])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 1, 64)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 1, 10)\n",
    "    loss_mix_ratio = trial.suggest_float(\"loss_mix_ratio\", 0, 1)\n",
    "    l1 = trial.suggest_float(\"l1\", 1e-5, 5e-1, log=True)\n",
    "\n",
    "    block1 = trial.suggest_int(\"block1\", 1, 2)\n",
    "    block2 = trial.suggest_int(\"block2\", 1, 2)\n",
    "    block3 = trial.suggest_int(\"block3\", 1, 2)\n",
    "    flip = trial.suggest_categorical(\"flip\", [True, False])\n",
    "    rotate = trial.suggest_categorical(\"rotate\", [True, False])\n",
    "    autoencoder_epoch = trial.suggest_int(\"autoencoder_epoch\", 0, len(saved_epoch)-1)\n",
    "\n",
    "    with_orginal = trial.suggest_categorical(\"with_orginal\", [True, False])\n",
    "    class_weight = trial.suggest_categorical(\"class_weight\", [\"balanced\", None])\n",
    "\n",
    "    feature = all_features[block1-1, block2-1, block3-1, int(flip), int(rotate), autoencoder_epoch]\n",
    "    feature, _, _ = standardize_images(feature, labeled_masks)\n",
    "\n",
    "    if with_orginal:\n",
    "        feature = torch.cat([feature, labeled_images], dim=1)\n",
    "    \n",
    "    # Map string to actual optimizer class\n",
    "    optimizer_class = torch.optim.SGD if optimizer_name == \"SGD\" else torch.optim.AdamW\n",
    "\n",
    "    # Cross-validation indices (modify as needed)\n",
    "    train_val_idx = [0, 1]\n",
    "    \n",
    "    # Container for metrics from each fold\n",
    "    fold_records_f1 = torch.zeros(len(train_val_idx))  # For F1 (objective)\n",
    "    fold_records_acc = torch.zeros(len(train_val_idx))  # For accuracy (logging)\n",
    "\n",
    "    # Assuming feature and labels are defined globally (e.g., torch tensors)\n",
    "    for i in train_val_idx:\n",
    "        # Leave-one-out style split\n",
    "        train_idx = [j for j in train_val_idx if j != i]\n",
    "        val_idx = [i]\n",
    "\n",
    "        # Get training and validation data\n",
    "        train_data = feature[train_idx]\n",
    "        train_labels = labels[train_idx]\n",
    "        val_data = feature[val_idx]\n",
    "        val_labels = labels[val_idx]\n",
    "\n",
    "        # Train and validate, get both F1 and accuracy\n",
    "        val_f1, val_acc = train_and_validate(\n",
    "            train_data=train_data,\n",
    "            train_labels=train_labels,\n",
    "            val_data=val_data,\n",
    "            val_labels=val_labels,\n",
    "            in_channels=feature.shape[1],\n",
    "            num_layers=num_layers,\n",
    "            kernel_size=kernel_size,\n",
    "            hidden_channels=hidden_channels,\n",
    "            epochs=epochs,\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            optimizer_class=optimizer_class,\n",
    "            loss_mix_ratio=loss_mix_ratio,\n",
    "            l1=l1,\n",
    "            class_weight=class_weight,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        fold_records_f1[i] = val_f1\n",
    "        fold_records_acc[i] = val_acc\n",
    "    \n",
    "    avg_f1 = fold_records_f1.mean().item()\n",
    "    avg_acc = fold_records_acc.mean().item()\n",
    "\n",
    "    trial.set_user_attr(\"val_acc\", avg_acc)\n",
    "    #print(f\"Trial {trial.number}: F1 = {avg_f1}, Acc = {avg_acc}\")\n",
    "    \n",
    "    # Return average F1 score across folds\n",
    "    return avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the study by running a number of trials (e.g., 100 trials).\n",
    "study.optimize(objective, n_trials=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the study\n",
    "import pickle\n",
    "with open(\"optuna_study_autoencoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(study, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance of hyperparameters\n",
    "optuna.visualization.matplotlib.plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
