{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.efficientnet import MBConvConfig, FusedMBConvConfig\n",
    "\n",
    "import optuna\n",
    "\n",
    "sys.path.append(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling\")\n",
    "from preprocessing import to_NCHW, pad_to_384x384, standardize_images\n",
    "from autoencoder import EfficientNetEncoder, EfficientNetDecoder, AutoencoderConfig\n",
    "from classification import train_and_validate\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "use_amp = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = np.load(\"/jet/home/azhang19/stat 214/stat-214-lab2-group6/data/array_data.npz\")\n",
    "unlabeled_images, unlabeled_masks, labeled_images, labeled_masks, labels = data[\"unlabeled_images\"], data[\"unlabeled_masks\"], data[\"labeled_images\"], data[\"labeled_masks\"], data[\"labels\"]\n",
    "\n",
    "unlabeled_images = pad_to_384x384(to_NCHW(unlabeled_images))\n",
    "unlabeled_masks = pad_to_384x384(unlabeled_masks)\n",
    "\n",
    "labeled_images = pad_to_384x384(to_NCHW(labeled_images))\n",
    "labeled_masks = pad_to_384x384(labeled_masks)\n",
    "labels = pad_to_384x384(labels)\n",
    "\n",
    "# Convert to tensors and move to GPU\n",
    "unlabeled_images = torch.tensor(unlabeled_images, dtype=torch.float32).to(device)  # [161, 8, 384, 384]\n",
    "unlabeled_masks = torch.tensor(unlabeled_masks, dtype=torch.bool).to(device)    # [161, 384, 384]\n",
    "\n",
    "labeled_images = torch.tensor(labeled_images, dtype=torch.float32).to(device)      # [3, 8, 384, 384]\n",
    "labeled_masks = torch.tensor(labeled_masks, dtype=torch.bool).to(device)        # [3, 384, 384]\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)                      # [3, 384, 384]\n",
    "\n",
    "\n",
    "# Standardize images\n",
    "unlabeled_images, std_channel, mean_channel = standardize_images(unlabeled_images, unlabeled_masks)\n",
    "labeled_images, _, _ = standardize_images(labeled_images, labeled_masks, std_channel, mean_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and extract features\n",
    "ckpt_path = \"/jet/home/azhang19/stat 214/stat-214-lab2-group6/code/modeling/ckpt\"\n",
    "saved_epoch = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 15000, 20000, 25000, 30000, 35000, 40000]\n",
    "\n",
    "all_features = torch.zeros((2, 2, 2, 2, 2, len(saved_epoch), 3, 64, 384, 384)).to(device)\n",
    "\n",
    "num_layers_per_block = [1, 2]\n",
    "augementation = [True, False]\n",
    "for block1, block2, block3, flip, rotate in itertools.product(*[num_layers_per_block] * 3,*[augementation] * 2):\n",
    "    config = AutoencoderConfig(\n",
    "        num_layers_block=[block1, block2, block3],\n",
    "        augmentation_flip=flip,\n",
    "        augmentation_rotate=rotate\n",
    "    )\n",
    "    encoder_config = [\n",
    "        FusedMBConvConfig(1, 3, 1, 16, 16, config.num_layers_block[0]),  # 384x384x8 -> 384x384x16\n",
    "        FusedMBConvConfig(4, 3, 2, 16, 32, config.num_layers_block[1]),  # 384x384x16 -> 192x192x32\n",
    "        MBConvConfig(4, 3, 2, 32, 64, config.num_layers_block[2]),       # 192x192x32 -> 96x96x64\n",
    "    ]\n",
    "\n",
    "    encoder = EfficientNetEncoder(\n",
    "        inverted_residual_setting=encoder_config,\n",
    "        dropout=0.1,\n",
    "        input_channels=8,\n",
    "        last_channel=64,\n",
    "    )\n",
    "\n",
    "    decoder = EfficientNetDecoder()\n",
    "    autoencoder = nn.Sequential(encoder, decoder).train().to(device)\n",
    "\n",
    "    folder_path = os.path.join(ckpt_path, str(config))\n",
    "    \n",
    "    for i, epoch in enumerate(saved_epoch):\n",
    "        autoencoder.load_state_dict(torch.load(os.path.join(folder_path, f\"autoencoder_{epoch}.pth\")))\n",
    "        autoencoder.eval()\n",
    "        with torch.inference_mode():\n",
    "            encoder = autoencoder[0]\n",
    "            features = encoder(labeled_images)\n",
    "            features = nn.functional.interpolate(features, size=384, mode=\"bicubic\", antialias=True)\n",
    "            all_features[block1-1, block2-1, block3-1, int(flip), int(rotate), i] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved study\n",
    "import pickle\n",
    "with open(\"/jet/home/azhang19/optuna_study_autoencoder.pkl\", \"rb\") as f:\n",
    "    study = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best trial\n",
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best feature\n",
    "feature = all_features[study.best_params[\"block1\"]-1, study.best_params[\"block2\"]-1, study.best_params[\"block3\"]-1, int(study.best_params[\"flip\"]), int(study.best_params[\"rotate\"]), study.best_params[\"autoencoder_epoch\"]]\n",
    "\n",
    "feature, _, _ = standardize_images(feature, labeled_masks)\n",
    "\n",
    "if study.best_params['with_orginal']:\n",
    "    feature = torch.cat([feature, labeled_images], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat CV with best hyperparameters\n",
    "num_repeat = 100\n",
    "record = np.zeros((num_repeat, 2))\n",
    "classifiers = []\n",
    "\n",
    "for repeat in range(num_repeat):\n",
    "\n",
    "    train_val_idx = [0, 1]\n",
    "\n",
    "    # Container for metrics from each fold\n",
    "    fold_records_f1 = torch.zeros(len(train_val_idx))  # For F1 (objective)\n",
    "    fold_records_acc = torch.zeros(len(train_val_idx))  # For accuracy (logging)\n",
    "\n",
    "    classifiers_in_this_repeat = []\n",
    "    # Assuming feature and labels are defined globally (e.g., torch tensors)\n",
    "    for i in train_val_idx:\n",
    "        # Leave-one-out style split\n",
    "        train_idx = [j for j in train_val_idx if j != i]\n",
    "        val_idx = [i]\n",
    "\n",
    "        # Get training and validation data\n",
    "        train_data = feature[train_idx]\n",
    "        train_labels = labels[train_idx]\n",
    "        val_data = feature[val_idx]\n",
    "        val_labels = labels[val_idx]\n",
    "\n",
    "        # Train and validate, get both F1 and accuracy\n",
    "        classifier, val_f1, val_acc = train_and_validate(\n",
    "            train_data=train_data,\n",
    "            train_labels=train_labels,\n",
    "            val_data=val_data,\n",
    "            val_labels=val_labels,\n",
    "            in_channels=feature.shape[1],\n",
    "            num_layers=study.best_params[\"num_layers\"],\n",
    "            kernel_size=study.best_params[\"kernel_size\"],\n",
    "            hidden_channels=study.best_params[\"hidden_channels\"],\n",
    "            epochs=study.best_params[\"epochs\"],\n",
    "            lr=study.best_params[\"lr\"],\n",
    "            weight_decay=study.best_params[\"weight_decay\"],\n",
    "            optimizer_class=torch.optim.AdamW if study.best_params['optimizer'] == 'AdamW' else torch.optim.SGD,\n",
    "            loss_mix_ratio=study.best_params[\"loss_mix_ratio\"],\n",
    "            l1=study.best_params[\"l1\"],\n",
    "            class_weight=study.best_params['class_weight'],\n",
    "            device=device,\n",
    "            return_classifier=True,\n",
    "        )\n",
    "        classifiers_in_this_repeat.append((train_idx, classifier))\n",
    "\n",
    "        fold_records_f1[i] = val_f1\n",
    "        fold_records_acc[i] = val_acc\n",
    "\n",
    "    classifiers.append(classifiers_in_this_repeat)\n",
    "    avg_f1 = fold_records_f1.mean().item()\n",
    "    avg_acc = fold_records_acc.mean().item()\n",
    "\n",
    "    record[repeat] = [avg_f1, avg_acc]\n",
    "\n",
    "record.mean(axis=0), record.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the whole dataset\n",
    "\n",
    "classifiers = []\n",
    "record = np.zeros((num_repeat, 2))\n",
    "\n",
    "for repeat in range(num_repeat):\n",
    "    classifiers_in_this_repeat = []\n",
    "    # Get training and validation data\n",
    "    train_data = feature[0:2]\n",
    "    train_labels = labels[0:2]\n",
    "    val_data = feature[[2]]\n",
    "    val_labels = labels[[2]]\n",
    "\n",
    "    # Train and validate, get both F1 and accuracy\n",
    "    classifier, val_f1, val_acc = train_and_validate(\n",
    "        train_data=train_data,\n",
    "        train_labels=train_labels,\n",
    "        val_data=val_data,\n",
    "        val_labels=val_labels,\n",
    "        in_channels=feature.shape[1],\n",
    "        num_layers=study.best_params[\"num_layers\"],\n",
    "        kernel_size=study.best_params[\"kernel_size\"],\n",
    "        hidden_channels=study.best_params[\"hidden_channels\"],\n",
    "        epochs=study.best_params[\"epochs\"],\n",
    "        lr=study.best_params[\"lr\"],\n",
    "        weight_decay=study.best_params[\"weight_decay\"],\n",
    "        optimizer_class=torch.optim.AdamW if study.best_params['optimizer'] == 'AdamW' else torch.optim.SGD,\n",
    "        loss_mix_ratio=study.best_params[\"loss_mix_ratio\"],\n",
    "        l1=study.best_params[\"l1\"],\n",
    "        class_weight=study.best_params['class_weight'],\n",
    "        device=device,\n",
    "        return_classifier=True,\n",
    "    )\n",
    "    classifiers_in_this_repeat.append((train_idx, classifier))\n",
    "\n",
    "    record[repeat] = [val_f1.item(), val_acc.item()]\n",
    "\n",
    "    classifiers.append(classifiers_in_this_repeat)\n",
    "\n",
    "record.mean(axis=0), record.std(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
